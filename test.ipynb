{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import features_nodewise as nw\n",
    "import features_pairwise as pw\n",
    "import preprocessing as prep\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import igraph\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "from functools import reduce\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"./data/train_train_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "with open(\"./data/train_test_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "to_keep_train = random.sample( range(len(training_set)),k=int(round(len(training_set)*0.05)) )\n",
    "training_set_reduced = [training_set[i] for i in to_keep_train]\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "to_keep_test = random.sample( range(len(testing_set)),k=int(round(len(testing_set)*1)) )\n",
    "testing_set_reduced = [testing_set[i] for i in to_keep_test]\n",
    "\n",
    "with open(\"./data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "IDs = [element[0] for element in node_info]\n",
    "node_dict = prep.to_dict( [element[0] for element in node_info],range(len(node_info)) )\n",
    "index_dict = prep.to_dict(range(len(IDs)),IDs)\n",
    "\n",
    "# compute TFIDF vector of each paper\n",
    "corpus = [element[5] for element in node_info]\n",
    "\n",
    "t = prep.tfidf(corpus)\n",
    "l = nw.LSA(t)\n",
    "\n",
    "nodes = set([training_set_reduced[i][0] for i in range(len(training_set_reduced))])\n",
    "nodes = nodes | set([training_set_reduced[i][1] for i in range(len(training_set_reduced))])\n",
    "training_l = [l[node_dict[i]] for i in nodes]\n",
    "kdtree = nw.KDTree(training_l)\n",
    "\n",
    "all_edges = [(element[0],element[1]) for element in training_set_reduced if element[2]==\"1\"]\n",
    "edges = random.sample(all_edges,int(len(all_edges)/2))\n",
    "graph = prep.article_graph(IDs,edges)\n",
    "\n",
    "no_citation = [(element[0],element[1]) for element in training_set if element[2]==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "true_labels = []\n",
    "\n",
    "for i,triple in enumerate(training_set_reduced):\n",
    "    #currently: 0:CC%,1:CC%,2:Max_Sim..6:Max_Sim,7:avg(max_sim),8:overlap_title,9:bool(temp_diff),10:comm_auth,\n",
    "    # 11: a and b are connected\n",
    "    #currently testing with boolean 1-0 normalization of temp_diff\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    f = []\n",
    "    \n",
    "    f.extend(pw.Citation_Check(source,target,kdtree,l,graph,node_dict,index_dict,k=20))\n",
    "    sim=list(pw.Max_Sim(source,target,l,graph,node_dict))\n",
    "    f.extend(sim)\n",
    "    f.append(np.mean(sim))\n",
    "    f.append(pw.peer_popularity(graph,source,target))\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    \n",
    "    f.append(overlap_title)\n",
    "    f.append(int(temp_diff>0))\n",
    "    f.append(comm_auth)\n",
    "    f.append(pw.edge_check(source,target,graph))\n",
    "    features.append(f)\n",
    "    true_labels.append(triple[2])\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "features=np.array(features)\n",
    "true_labels=np.array(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []\n",
    "true_labels = []\n",
    "\n",
    "for i,triple in enumerate(training_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    feature.append(pw.peer_popularity(graph,source,target))\n",
    "    true_labels.append(triple[2])\n",
    "    if i%1000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def store_feature(feature_func,filename,)\n",
    "\n",
    "with open('./features/peer_popularity', 'wb') as f:\n",
    "    pickle.dump(feature,f)\n",
    "\n",
    "with open('./features/true_labels', 'wb') as f:\n",
    "    pickle.dump(true_labels,f)\n",
    "\n",
    "with open('./features/peer_popularity', 'rb') as f:\n",
    "    feature1 = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "#currently: 0:CC%,1:CC%,2:Max_Sim..6:Max_Sim,7:avg(max_sim),8:overlap_title,9:temp_diff,10:comm_auth\n",
    "#temp-diff should be normalized or preprocessed\n",
    "#as should common_auth?\n",
    "\n",
    "normalized_features = normalize(features,axis=0)\n",
    "max([features[i][8] for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set([training_set_reduced[i][0] for i in range(len(training_set_reduced))])\n",
    "nodes = nodes | set([training_set_reduced[i][1] for i in range(len(training_set_reduced))])\n",
    "test_l = [l[node_dict[i]] for i in nodes]\n",
    "test_kdtree = nw.KDTree(test_l)\n",
    "\n",
    "test_all_edges = [(element[0],element[1]) for element in testing_set_reduced if element[2]==\"1\"]\n",
    "test_edges = random.sample(test_all_edges,int(len(test_all_edges)/2))\n",
    "test_graph = prep.article_graph(IDs,test_edges)\n",
    "\n",
    "test_features = []\n",
    "test_true_labels = []\n",
    "for i,triple in enumerate(testing_set_reduced):\n",
    "    \n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    f = []\n",
    "    \n",
    "    f.extend(pw.Citation_Check(source,target,test_kdtree,l,test_graph,node_dict,index_dict,k=20))\n",
    "    sim=list(pw.Max_Sim(source,target,l,test_graph,node_dict))\n",
    "    f.extend(sim)\n",
    "    f.append(np.mean(sim))\n",
    "    f.append(pw.peer_popularity(graph,source,target))\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    \n",
    "    f.append(overlap_title)\n",
    "    f.append(int(temp_diff>0))\n",
    "    f.append(comm_auth)\n",
    "    f.append(pw.edge_check(source,target,test_graph))\n",
    "    test_features.append(f)\n",
    "    test_true_labels.append(triple[2])\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        \n",
    "test_features=np.array(test_features)\n",
    "test_true_labels=np.array(test_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# for citation_check:\n",
    "# mean of true but removed edges (with 50% edges removed) is 0.031\n",
    "# mean of no edge pairs (with 50% edges removed) is 0.0003\n",
    "\n",
    "[pw.Citation_Check(e[0],e[1],kdtree,l,graph,node_dict,index_dict,k=20) for e in random.sample(edges[150000:],20)]\n",
    "np.mean([pw.Citation_Check(e[0],e[1],kdtree,l,graph,node_dict,index_dict,k=20) for e in random.sample(no_citation,1500)])\n",
    "\n",
    "#for Max_Sim:\n",
    "#mean of true... is 1.13\n",
    "#mean of no edge... is 0.58\n",
    "a = np.mean([np.mean(pw.Max_Sim(e[0],e[1],l,graph,node_dict)) for e in random.sample(edges[150000:],1500)])\n",
    "b = np.mean([np.mean(pw.Max_Sim(e[0],e[1],l,graph,node_dict)) for e in random.sample(no_citation,1500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "# from sklearn import cross_validation, \n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "# from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "def modelfit(alg, features, true_labels,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "#     if useTrainCV:\n",
    "#         xgb_param = alg.get_xgb_params()\n",
    "#         xgtrain = xgb.DMatrix(features, label=true_labels)\n",
    "#         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "#             metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "#         alg.set_params(n_estimators=cvresult)\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(features, true_labels,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(features)\n",
    "    dtrain_predprob = alg.predict_proba(features)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(true_labels, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(true_labels, dtrain_predprob))\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " max_depth=8,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    ")\n",
    "\n",
    "modelfit(xgb1, features, true_labels,useTrainCV=True)\n",
    "\n",
    "preds = xgb1.predict(test_features)\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "# train\n",
    "classifier.fit(features, true_labels)\n",
    "preds= list(classifier.predict(test_features))\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "model = lr().fit(features,true_labels)\n",
    "preds = list(model.predict(test_features))\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "nNhbr = KNeighborsClassifier()\n",
    "nNhbr.fit(features,true_labels) # do Ytrain.ravel() for length one Y values\n",
    "preds = nNhbr.predict(test_features)\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(features,true_labels) # do Ytrain.ravel() for length one Y values\n",
    "preds = dTree.predict(test_features)\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "class Class_Net():\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, batch_size=60):\n",
    "        ''' initialize the classifier with default (best) parameters '''\n",
    "        tf.reset_default_graph()\n",
    "        self.alpha = learning_rate\n",
    "        self.beta = batch_size\n",
    "        self.warm = False\n",
    "\n",
    "    def fit(self,X,Y,warm_start=True,n_epochs=50):\n",
    "        ''' train the network, and if warm_start, then do not reinit. the network\n",
    "            (if it has already been initialized)\n",
    "        '''\n",
    "        self.epochs=n_epochs\n",
    "\n",
    "        self.n_batch = int(len(X)/self.beta)\n",
    "        \n",
    "        if warm_start==False or self.warm==False:\n",
    "            self.x = tf.placeholder(tf.float32,shape=[None,len(X[0])])\n",
    "            self.y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "            \n",
    "            self.wZero = tf.get_variable('wZero',shape=[len(X[0]),50],initializer=tf.glorot_uniform_initializer())\n",
    "            self.bZero = tf.Variable(tf.zeros([50]))\n",
    "\n",
    "            self.wOne = tf.get_variable('wOne',shape=[50,1],initializer=tf.glorot_uniform_initializer())\n",
    "            self.bOne = tf.Variable(tf.zeros([1]))\n",
    "            self.keep_prob = 0.9\n",
    "            self.drop_out = tf.nn.dropout(self.x, self.keep_prob)\n",
    "            self.model = tf.nn.sigmoid(tf.matmul(tf.nn.relu(tf.matmul(self.drop_out, self.wZero) \n",
    "                                              + self.bZero),self.wOne)+self.bOne)\n",
    "            self.cost = tf.losses.log_loss(self.y,self.model)\n",
    "            \n",
    "#             self.optimizer = tf.train.GradientDescentOptimizer(self.alpha).minimize(self.cost)\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.alpha).minimize(self.cost)\n",
    "\n",
    "            #without dropout\n",
    "#             self.model = tf.matmul(tf.nn.relu(tf.matmul(self.x, self.wZero) + self.bZero),self.wOne)+self.bOne\n",
    "\n",
    "    \n",
    "            self.saver = tf.train.Saver()\n",
    "            self.init = tf.global_variables_initializer()\n",
    "            \n",
    "        with tf.Session() as sess:\n",
    "            if warm_start==False or self.warm==False:\n",
    "                sess.run(self.init)\n",
    "            else:\n",
    "                self.saver.restore(sess, './tempVariables.ckpt')\n",
    "            for epoch in range(self.epochs):\n",
    "                self.avg_cost = 0\n",
    "                for i in range(self.n_batch):\n",
    "                    _, self.c = sess.run([self.optimizer,self.cost], feed_dict={self.x: X[i*self.beta:min([(i+1)*\n",
    "                                    self.beta,len(X)]),:],self.y:Y[i*self.beta:min([(i+1)*self.beta,len(X)])]})\n",
    "                    \n",
    "                    self.avg_cost = self.avg_cost+np.mean(self.c)/self.n_batch\n",
    "                print(\"Epoch:\", '%s' % (epoch+1), \"cost=\", \"%s\"% (self.avg_cost))\n",
    "            self.saver.save(sess,'./tempVariables.ckpt')\n",
    "            \n",
    "        self.warm = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        ''' return a matrix P where P[i,j] = P(Y[i,j]=1), \n",
    "        for all instances i, and labels j. '''\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess, './tempVariables.ckpt')\n",
    "            self.preds = sess.run(tf.nn.softmax(self.model), feed_dict={self.x: X}) \n",
    "        return self.preds\n",
    "    \n",
    "    def predict(self,X):\n",
    "        ''' return a matrix of predictions for X '''\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Class_Net(learning_rate=0.01,batch_size=250)\n",
    "net.fit(features,list(map(lambda x: [x],true_labels)),n_epochs=35)\n",
    "preds=net.predict(test_features)\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
