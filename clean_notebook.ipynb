{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Imports ##\n",
    "#############\n",
    "\n",
    "# external libraries\n",
    "import random\n",
    "import math\n",
    "import igraph\n",
    "import nltk\n",
    "import importlib\n",
    "import csv\n",
    "import pickle\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# our outsourced code\n",
    "import features_nodewise as nw\n",
    "import features_pairwise as pw\n",
    "import preprocessing as prep\n",
    "import multi_func as mf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## Read data ##\n",
    "###############\n",
    "\n",
    "# Training\n",
    "with open(\"./data/training_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "    training_set = [element[0].split(\" \") for element in training_set]\n",
    "    \n",
    "# Testing -> we call it competition_set\n",
    "with open (\"./data/testing_set.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    competition_set = list(reader)\n",
    "    competition_set = [element[0].split(\" \") for element in competition_set]\n",
    "\n",
    "# Node info\n",
    "with open(\"./data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "IDs_present = []\n",
    "for edge in competition_set:\n",
    "    IDs_present.append(edge[0])\n",
    "    IDs_present.append(edge[1])\n",
    "for edge in training_set:\n",
    "    IDs_present.append(edge[0])\n",
    "    IDs_present.append(edge[1])\n",
    "IDs_present = list(set(IDs_present))\n",
    "\n",
    "new_node_info = []\n",
    "for info in node_info:\n",
    "    if info[0] in IDs_present:\n",
    "        new_node_info.append(info)\n",
    "node_info = new_node_info\n",
    "\n",
    "abstracts = [element[5] for element in node_info]\n",
    "titles = [element[2] for element in node_info]\n",
    "IDs = [element[0] for element in node_info]\n",
    "publication_years = prep.to_feature_shape([int(info[1]) for info in node_info])\n",
    "train_true_labels = [element[2] for element in training_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 6788, n_features: 1432\n",
      "n_samples: 6788, n_features: 6088\n",
      "n_samples: 6788, n_features: 61425\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 19%\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 13%\n",
      "[nltk_data] Downloading package punkt to /home/lucas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/lucas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "## Preprocess data ##\n",
    "#####################\n",
    "\n",
    "# Construct term-document-tfidf matrices\n",
    "t_titles = prep.tfidf(titles)\n",
    "t = prep.tfidf(abstracts)\n",
    "t_ngrams = prep.tfidf(abstracts, r= (2,3), midf = 2, madf=0.5,feats=150000, sublinear = True)\n",
    "\n",
    "# Reduce matrix dimensionality\n",
    "l = nw.LSA(t,n_components=100)\n",
    "l_ngrams = nw.LSA(t_ngrams,n_components=300)\n",
    "\n",
    "# Build KDTrees to accelerate nearest-neighbour searches\n",
    "kdtree = nw.KDTree(l)\n",
    "kdtree_n = nw.KDTree(l_ngrams)\n",
    "\n",
    "# Build graph from gold standard training data\n",
    "train_IDs = np.array(IDs_present)\n",
    "train_edges = [(element[0],element[1]) for element in training_set if element[2]=='1']\n",
    "train_graph = prep.article_graph(train_IDs,train_edges)\n",
    "\n",
    "# dicts to accelerate ID <-> index searches\n",
    "node_dict = prep.to_dict(IDs,range(len(node_info)))\n",
    "index_dict = prep.to_dict(range(len(IDs)),IDs)\n",
    "\n",
    "# Load stemmer and stopwords for later title & abstract processing\n",
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "## Create dicts to store features ##\n",
    "####################################\n",
    "train_features_dict = dict()\n",
    "competition_features_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6\n",
      "0 / 2\n",
      "0 / 2\n",
      "1 / 2\n",
      "0 / 1\n",
      "0 / 2696\n",
      "1000 / 2696\n",
      "2000 / 2696\n",
      "overlap_title 2696\n",
      "comm_auth 2696\n",
      "temp_diff 2696\n",
      "citation_check 2696\n",
      "max_sim 2696\n",
      "peer_popularity 2696\n",
      "succ_pred 2696\n",
      "LSA_distance 2696\n",
      "title_sim 2696\n",
      "temporal_fit 2696\n",
      "N_LSA_distance 2696\n",
      "path_length 2696\n",
      "node_degree 2696\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "## Compute features on TRAINING_SET ##\n",
    "######################################\n",
    "\n",
    "features_to_create = ['overlap_title',\n",
    "                      'comm_auth',\n",
    "                      'temp_diff',\n",
    "                      'citation_check',\n",
    "                      'max_sim',\n",
    "                      'peer_popularity',\n",
    "                      'succ_pred',\n",
    "                      'LSA_distance',\n",
    "                      'title_sim',\n",
    "                      'temporal_fit',\n",
    "                      'N_LSA_distance',\n",
    "                      'path_length',\n",
    "                      'node_degree']\n",
    "\n",
    "# We insert features in a dictionary\n",
    "insert_features_dict = train_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = training_set\n",
    "\n",
    "# Compute some features in parallelized chunks.\n",
    "p = mf.params(train_graph, kdtree, l, node_dict, index_dict, chunk_size = 1000)\n",
    "grouped_set = [training_set[2000*i:2000*(i+1)] for i in range(math.ceil(len(training_set)/2000))]\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "path_dict_list = pool.map(p.all_paths_noparams, grouped_set, chunksize = 10)\n",
    "chunked_output = zip(*pool.map(p.by_chunk_noparams, grouped_set, chunksize = 10))\n",
    "pool.close()\n",
    "\n",
    "# Recombine chunked output\n",
    "all_path_dict = dict()\n",
    "for i in IDs:\n",
    "    all_path_dict[i] = dict()\n",
    "    \n",
    "for d in path_dict_list:\n",
    "    for source_id in d:\n",
    "        for target_id in d[source_id]:\n",
    "            all_path_dict[source_id][target_id] = d[source_id][target_id]\n",
    "\n",
    "list_chunked_output = list(chunked_output)\n",
    "for feature_list in list_chunked_output[0]:\n",
    "        insert_features_dict['succ_pred'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[1]:\n",
    "        insert_features_dict['max_sim'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[2]:\n",
    "        insert_features_dict['citation_check'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[3]:\n",
    "        insert_features_dict['node_degree'].extend(feature_list)\n",
    "\n",
    "\n",
    "# Compute features per node pair\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    \n",
    "    # Read basic data about the current node pair\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "    peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "    insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "    LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "    title_weighted = t_titles.getrow(index_source).dot(t_titles.getrow(index_target).transpose())[0,0]\n",
    "    insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "\n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "    temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "    insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    path_length = pw.path_length(source, target, all_path_dict)\n",
    "    insert_features_dict[\"path_length\"].append(path_length)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = prep.to_feature_shape(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(preprocessing)\n",
    "importlib.reload(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "0 / 5\n",
      "0 / 2\n",
      "1 / 2\n",
      "0 / 1535\n",
      "1000 / 1535\n",
      "overlap_title 1535\n",
      "comm_auth 1535\n",
      "temp_diff 1535\n",
      "citation_check 1535\n",
      "max_sim 1535\n",
      "node_degreepeer_popularity 0\n",
      "succ_pred 1535\n",
      "node_degree 1535\n",
      "LSA_distance 1535\n",
      "title_sim 1535\n",
      "temporal_fit 1535\n",
      "N_LSA_distance 1535\n",
      "path_length 1535\n",
      "peer_popularity 1535\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## Construct features on COMPETITION_SET ##\n",
    "###########################################\n",
    "\n",
    "features_to_create = ['overlap_title',\n",
    "                      'comm_auth',\n",
    "                      'temp_diff',\n",
    "                      'citation_check',\n",
    "                      'max_sim',\n",
    "                      'node_degree',\n",
    "                      'peer_popularity',\n",
    "                      'succ_pred',\n",
    "                      'node_degree',\n",
    "                      'LSA_distance',\n",
    "                      'title_sim',\n",
    "                      'temporal_fit',\n",
    "                      'N_LSA_distance',\n",
    "                      'path_length']\n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = competition_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = competition_set\n",
    "\n",
    "# Compute some features in parallelized chunks.\n",
    "p = mf.params(train_graph, kdtree, l, node_dict, index_dict, chunk_size=1000, pairs_subset_edges=False)\n",
    "grouped_set = [competition_set[2000*i:2000*(i+1)] for i in range(math.ceil(len(competition_set)/2000))]\n",
    "print(len(grouped_set))\n",
    "print(mp.cpu_count())\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "path_dict_list = pool.map(p.all_paths_noparams, grouped_set, chunksize = 1)\n",
    "chunked_output = zip(*pool.map(p.by_chunk_noparams, grouped_set, chunksize = 1))\n",
    "pool.close()\n",
    "# Recombine chunked output\n",
    "all_path_dict = dict()\n",
    "for i in IDs:\n",
    "    all_path_dict[i] = dict()\n",
    "    \n",
    "for d in path_dict_list:\n",
    "    for source_id in d:\n",
    "        for target_id in d[source_id]:\n",
    "            all_path_dict[source_id][target_id] = d[source_id][target_id]\n",
    "\n",
    "list_chunked_output = list(chunked_output)\n",
    "for feature_list in list_chunked_output[0]:\n",
    "        insert_features_dict['succ_pred'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[1]:\n",
    "        insert_features_dict['max_sim'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[2]:\n",
    "        insert_features_dict['citation_check'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[3]:\n",
    "        insert_features_dict['node_degree'].extend(feature_list)\n",
    "\n",
    "# Compute features per node pair\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "    peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "    insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "    LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "    title_weighted = t_titles.getrow(index_source).dot(t_titles.getrow(index_target).transpose())[0,0]\n",
    "    insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "    \n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "    temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "    insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    path_length = pw.path_length(source, target, all_path_dict)\n",
    "    insert_features_dict[\"path_length\"].append(path_length)\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = prep.to_feature_shape(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "## Combine & normalize features ##\n",
    "##################################\n",
    "\n",
    "train_features = np.concatenate([train_features_dict['overlap_title'],\n",
    "                                 train_features_dict['comm_auth'],\n",
    "                                 train_features_dict['temp_diff'],\n",
    "                                 train_features_dict['citation_check'],\n",
    "                                 train_features_dict['max_sim'],\n",
    "                                 train_features_dict['peer_popularity'],\n",
    "                                 train_features_dict['succ_pred'],\n",
    "                                 train_features_dict['LSA_distance'],\n",
    "                                 train_features_dict['title_sim'],\n",
    "                                 train_features_dict['temporal_fit'],\n",
    "                                 train_features_dict['N_LSA_distance'],\n",
    "                                 train_features_dict['path_length'],\n",
    "                                 train_features_dict['node_degree']]                                            \n",
    "                                 ,axis = 1)\n",
    "\n",
    "competition_features = np.concatenate( [competition_features_dict['overlap_title'],\n",
    "                                        competition_features_dict['comm_auth'],\n",
    "                                        competition_features_dict['temp_diff'],\n",
    "                                        competition_features_dict['citation_check'],\n",
    "                                        competition_features_dict['max_sim'],\n",
    "                                        competition_features_dict['peer_popularity'],\n",
    "                                        competition_features_dict['succ_pred'],\n",
    "                                        competition_features_dict['LSA_distance'],\n",
    "                                        competition_features_dict['title_sim'],\n",
    "                                        competition_features_dict['temporal_fit'],\n",
    "                                        competition_features_dict['N_LSA_distance'],\n",
    "                                        competition_features_dict['path_length'],\n",
    "                                        competition_features_dict['node_degree']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS()\n",
    "normalized_train_features = scaler.fit_transform(train_features)\n",
    "normalized_competition_features = scaler.fit_transform(competition_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "## Train classifier & predict ##\n",
    "################################\n",
    "\n",
    "import lightgbm as light\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "# Select a subset of features to use\n",
    "selection = [2,  3,  5,  6,  7, 10, 11, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n",
    "             30]\n",
    "\n",
    "lgb = light.LGBMClassifier()\n",
    "# Training\n",
    "lgb.fit(train_features[:,selection], train_true_labels)\n",
    "# Predictions\n",
    "preds_lgb = lgb.predict(competition_features[:,selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUE FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## Extend the training graph ##\n",
    "###############################\n",
    "\n",
    "# We now incorporate the predictions just made in the training set, recompute features and\n",
    "\n",
    "predicted_edges = [tuple(competition_set[i]) for i in range(len(preds_lgb)) if int(preds_lgb[i]) == 1]\n",
    "train_graph.add_edges(predicted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## REcompute all features (2) ##\n",
    "################################\n",
    "\n",
    "# Based on the extended train_graph we recompute all features\n",
    "\n",
    "\n",
    "########################################\n",
    "## REcompute features on TRAINING_SET ##\n",
    "########################################\n",
    "\n",
    "features_to_create = ['overlap_title',\n",
    "                      'comm_auth',\n",
    "                      'temp_diff',\n",
    "                      'citation_check',\n",
    "                      'max_sim',\n",
    "                      'peer_popularity',\n",
    "                      'edge_check',\n",
    "                      'succ_pred',\n",
    "                      'LSA_distance',\n",
    "                      'title_sim',\n",
    "                      'temporal_fit',\n",
    "                      'N_LSA_distance',\n",
    "                      'path_length']\n",
    "\n",
    "# We insert features in a dictionary\n",
    "insert_features_dict = train_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = training_set\n",
    "\n",
    "# Compute some features in parallelized chunks.\n",
    "p = mf.params(train_graph, kdtree, l, node_dict, index_dict, chunk_size = 1000)\n",
    "grouped_set = [training_set[2000*i:2000*(i+1)].tolist() for i in range(math.ceil(len(training_set)/2000))]\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "path_dict_list = pool.map(p.all_paths_noparams, grouped_set, chunksize = 10)\n",
    "chunked_output = zip(*pool.map(p.by_chunk_noparams, grouped_set, chunksize = 10))\n",
    "pool.close()\n",
    "# Recombine chunked output\n",
    "all_path_dict = dict()\n",
    "for i in IDs:\n",
    "    all_path_dict[i] = dict()\n",
    "    \n",
    "for d in path_dict_list:\n",
    "    for source_id in d:\n",
    "        for target_id in d[source_id]:\n",
    "            all_path_dict[source_id][target_id] = d[source_id][target_id]\n",
    "\n",
    "for feature_list in list_chunked_output[0]:\n",
    "        insert_features_dict['succ_pred'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[1]:\n",
    "        insert_features_dict['Max_Sim'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[2]:\n",
    "        insert_features_dict['Citation_Check'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[3]:\n",
    "        insert_features_dict['node_degree'].extend(feature_list)\n",
    "\n",
    "\n",
    "# Compute features per node pair\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    \n",
    "    # Read basic data about the current node pair\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "    peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "    insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "    LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "    title_weighted = t_titles.getrow(index_source)*t_titles.getrow(index_target).transpose()\n",
    "    insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "\n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "    temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "    insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    path_length = pw.path_length(source, target, all_path_dict)\n",
    "    insert_features_dict[\"path_length\"].append(path_length)\n",
    "    \n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "    \n",
    "\n",
    "\n",
    "###########################################\n",
    "## REcompute features on COMPETITION_SET ##\n",
    "###########################################\n",
    "features_to_create = ['overlap_title',\n",
    "                      'comm_auth',\n",
    "                      'temp_diff',\n",
    "                      'citation_check',\n",
    "                      'max_sim',\n",
    "                      'peer_popularity',\n",
    "                      'edge_check',\n",
    "                      'succ_pred',\n",
    "                      'node_degree',\n",
    "                      'LSA_distance',\n",
    "                      'title_sim',\n",
    "                      'temporal_fit',\n",
    "                      'N_LSA_distance',\n",
    "                      'path_length']\n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = competition_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = competition_set\n",
    "\n",
    "# Compute some features in parallelized chunks.\n",
    "p = mf.params(train_graph, kdtree, l, node_dict, index_dict, chunk_size=1000, pairs_subset_edges=False)\n",
    "grouped_set = [competition_set[2000*i:2000*(i+1)].tolist() for i in range(math.ceil(len(competition_set)/2000))]\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "path_dict_list = pool.map(p.all_paths_noparams, grouped_set, chunksize = 1)\n",
    "chunked_output = zip(*pool.map(p.by_chunk_noparams, grouped_set, chunksize = 1))\n",
    "pool.close()\n",
    "# Recombine chunked output\n",
    "all_path_dict = dict()\n",
    "for i in IDs:\n",
    "    all_path_dict[i] = dict()\n",
    "    \n",
    "for d in path_dict_list:\n",
    "    for source_id in d:\n",
    "        for target_id in d[source_id]:\n",
    "            all_path_dict[source_id][target_id] = d[source_id][target_id]\n",
    "\n",
    "for feature_list in list_chunked_output[0]:\n",
    "        insert_features_dict['succ_pred'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[1]:\n",
    "        insert_features_dict['Max_Sim'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[2]:\n",
    "        insert_features_dict['Citation_Check'].extend(feature_list)\n",
    "for feature_list in list_chunked_output[3]:\n",
    "        insert_features_dict['node_degree'].extend(feature_list)\n",
    "\n",
    "# Compute features per node pair\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "    peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "    insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "    edge_check = pw.edge_check(source,target,train_graph)\n",
    "    insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "    LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "    title_weighted = title_sim[index_source,index_target]\n",
    "    insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "    \n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "    temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "    insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    path_length = pw.path_length(source, target, all_path_dict)\n",
    "    insert_features_dict[\"path_length\"].append(path_length)\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Combine & normalize features (again) ##\n",
    "##########################################\n",
    "\n",
    "train_features_dict.keys()\n",
    "test_features_dict.keys()\n",
    "for key,feat in train_features_dict.items():\n",
    "    print(key,feat.shape)\n",
    "train_features = np.concatenate([train_features_dict['overlap_title'],\n",
    "                                 train_features_dict['comm_auth'],\n",
    "                                 train_features_dict['temp_diff'],\n",
    "                                 train_features_dict['citation_check'],\n",
    "                                 train_features_dict['max_sim'],\n",
    "                                 train_features_dict['peer_popularity'],\n",
    "                                 train_features_dict['edge_check'],\n",
    "                                 train_features_dict['succ_pred'],\n",
    "                                 train_features_dict['LSA_distance'],\n",
    "                                 train_features_dict['title_sim'],\n",
    "                                 train_features_dict['temporal_fit'],\n",
    "                                 train_features_dict['N_LSA_distance'],\n",
    "                                 train_features_dict['path_length'],\n",
    "                                 train_features_dict['node_degree']]                                            \n",
    "                                 ,axis = 1)\n",
    "\n",
    "competition_features = np.concatenate( [competition_features_dict['overlap_title'],\n",
    "                                        competition_features_dict['comm_auth'],\n",
    "                                        competition_features_dict['temp_diff'],\n",
    "                                        competition_features_dict['citation_check'],\n",
    "                                        competition_features_dict['max_sim'],\n",
    "                                        competition_features_dict['peer_popularity'],\n",
    "                                        competition_features_dict['edge_check'],\n",
    "                                        competition_features_dict['succ_pred'],\n",
    "                                        competition_features_dict['LSA_distance'],\n",
    "                                        competition_features_dict['title_sim'],\n",
    "                                        competition_features_dict['temporal_fit'],\n",
    "                                        competition_features_dict['N_LSA_distance'],\n",
    "                                        competition_features_dict['path_length'],\n",
    "                                        competition_features_dict['node_degree']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "# normalization (again)\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS()\n",
    "normalized_train_features = scaler.fit_transform(training_features)\n",
    "normalized_competition_features = scaler.fit_transform(competition_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## Train classifier & predict (again) ##\n",
    "########################################\n",
    "\n",
    "import lightgbm as light\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "# Select a subset of features to use\n",
    "selection = [2,  3,  5,  6,  7, 10, 11, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n",
    "             30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "\n",
    "lgb = light.LGBMClassifier()\n",
    "# Training\n",
    "lgb.fit(training_features[:,selection], train_true_labels)\n",
    "# Predictions\n",
    "preds_lgb = lgb.predict(competition_features[:,selection])\n",
    "\n",
    "# Statistics\n",
    "t1 = time.time()-t0\n",
    "print(t1)\n",
    "acc = metrics.accuracy_score(list(map(int,train_true_labels)), list(map(int,preds_lgb)))\n",
    "f1 = metrics.f1_score(list(map(int,train_true_labels)), list(map(int,preds_lgb)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9707108849121655 f1: 0.9728685707333395\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "## Other classifiers ##\n",
    "#######################\n",
    "\n",
    "## SVM ##\n",
    "from sklearn import svm\n",
    "import copy\n",
    "\n",
    "classifier = svm.LinearSVC(loss='hinge')\n",
    "selection = list(range(train_features_reduced.shape[1]))\n",
    "svm_s = copy.copy(selection)\n",
    "\n",
    "# classifier.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "# preds_svm = list(classifier.predict(test_features[:,selection]))\n",
    "classifier.fit(normalized_train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "svm_c = classifier\n",
    "preds_svm = list(classifier.predict(normalized_test_features[:,selection]))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9649333333333333 f1: 0.9672028931288191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr \n",
    "selection = [ 1,  7,  9, 10, 11, 15, 16, 19, 21, 22, 23]\n",
    "selection.extend([6,25,26,27])\n",
    "selection.append(31)\n",
    "lr_s = copy.copy(selection)\n",
    "# selection = [i for i in range(16)]\n",
    "# selection.extend([41,103,115])\n",
    "\n",
    "model = lr(penalty='l1').fit(train_features_reduced[:,selection], train_true_labels_reduced[:])\n",
    "lr_c = model\n",
    "preds_lg = list(model.predict(test_features[:,selection]))\n",
    "\n",
    "# model = lr(penalty='l1').fit(train_features_reduced, train_true_labels)\n",
    "# preds_lg = list(model.predict(test_features))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9581021178788376 f1: 0.9613848202396804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "selection = [1, 2, 6, 13, 16, 20, 21, 22]\n",
    "knn_s = copy.copy(selection)\n",
    "\n",
    "nNhbr = KNeighborsClassifier(n_neighbors=9,weights='distance')\n",
    "nNhbr.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "knn_c = nNhbr\n",
    "preds_knn = nNhbr.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9557872270563126 f1: 0.9595274951532184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# selection = [0, 1, 2, 8, 13, 16, 20, 22]\n",
    "selection = [ 0,  2,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22,23, 25, 26, 27]\n",
    "dt_s = copy.copy(selection)\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "dt_c = dTree\n",
    "\n",
    "preds_dt = dTree.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.50986568e-06, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.99997490e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       [9.43410527e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [9.24313612e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       [7.56863879e-02, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.concatenate((probs_lr.reshape(-1,1),probs_dt.reshape(-1,1)),axis=1)\n",
    "np.concatenate((test,probs_dt.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_svm = svm_c.decision_function(normalized_test_features[:,svm_s])\n",
    "probs_lr = lr_c.predict_proba(test_features[:,lr_s])[:,0]\n",
    "probs_knn = knn_c.predict_proba(test_features[:,knn_s])[:,0]\n",
    "all_probs = [probs_svm,probs_lr,probs_knn]\n",
    "\n",
    "probs_features = all_probs[0].reshape(-1,1)\n",
    "for i in range(1,len(all_probs)):\n",
    "    probs_features = np.concatenate((probs_features,all_probs[i].reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9712067292138467 f1: 0.9731976148888756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "joint_model = lr(penalty='l1').fit(probs_features[:30000,:], test_true_labels[:30000])\n",
    "preds_lg = list(joint_model.predict(probs_features[30000:,:]))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[30000:])), list(map(int,preds_lg)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[30000:])), list(map(int,preds_lg)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.970852428964253 f1: 0.9730234136409909\n"
     ]
    }
   ],
   "source": [
    "# Joined forces\n",
    "joined_DTree = DecisionTreeClassifier()\n",
    "\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_dt = np.reshape(preds_dt,(len(preds_dt),1))\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_dt],axis=1)\n",
    "\n",
    "joined_DTree.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = joined_DTree.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are important?\n",
    "# Histogram of the feature frequency for all selections that reached > 90% acc\n",
    "frequency = [0]*total_num_features\n",
    "\n",
    "num_good_preds = 0\n",
    "min_acc = 0.93\n",
    "for i,acc in enumerate(accs):\n",
    "    if acc > min_acc:\n",
    "        num_good_preds += 1\n",
    "        for f in feature_selections[i]:\n",
    "            frequency[f] += 1\n",
    "#frequency = [freq/num_good_preds for freq in frequency]\n",
    "print(\"\")\n",
    "print(\"number of classifiers: \",len(accs))\n",
    "print(\"number of accs >\",min_acc,\": \",sum([1 for acc in accs if acc > min_acc]))\n",
    "plt.figure()\n",
    "plt.bar(x=range(len(frequency)),height=frequency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9740436709899852 f1: 0.9761527670935336\n"
     ]
    }
   ],
   "source": [
    "# Adaboost DecisionTrees\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "selection =  [ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26]\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4, min_samples_leaf = 1, min_samples_split = 2),\n",
    "                         n_estimators=750,learning_rate=0.01)\n",
    "ada.fit(train_features[:100000,selection],train_true_labels[:100000])\n",
    "preds_ada = ada.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)\n",
    "#0.9761527670935336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9645706780495813 f1: 0.9675674050918271\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "#fiddle with n_estimators and min_samples_leaf\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "selection = [1, 2,  5,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "#add one to min_sample_leaf for full train_features (or change to 4)\n",
    "extraTrees = ExtraTreesClassifier(n_estimators=750,max_depth=90,min_samples_split=10,min_samples_leaf=0.00001)\n",
    "extraTrees.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_extra = extraTrees.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9724019044491873 f1: 0.9746398129290187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#f1: 0.96989, takes ~35 mins\n",
    "selection = [2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "\n",
    "randForest = RandomForestClassifier(n_estimators = 750, min_samples_split = 5, min_samples_leaf = 4, max_depth = 60)\n",
    "\n",
    "randForest.fit(train_features[:,selection],train_true_labels)\n",
    "preds_randForest = randForest.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[:])), list(map(int,preds_randForest)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[:])), list(map(int,preds_randForest)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "preds_randForest = randForest.predict(competition_features[:,selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = list(preds_randForest)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_rf = list(zip(range(len(competition_set)), preds_rf))\n",
    "\n",
    "with open(\"rf_predictions0.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_rf:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "# with open('random_forest_model', 'wb') as file:\n",
    "#         pickle.dump(randForest,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9716795271712363 f1: 0.9739366926040642\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "selection = [2,22, 23, 25, 26, 7, 15, 21, 10, 5, 6,  16, 19, 27, 28, 29, 30, 31]\n",
    "# selection = [i for i in range(16)]\n",
    "# selection.extend([ 95, 102])\n",
    "\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "xgb.fit(train_features[:100000,selection],train_true_labels[:100000])\n",
    "preds_xgb = xgb.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[:])), list(map(int,preds_xgb)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[:])), list(map(int,preds_xgb)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9834 f1: 0.9846438482886217\n"
     ]
    }
   ],
   "source": [
    "selection = [0,2,7,8,9,13,16,19,20,21,22,23,24,25,26,27]\n",
    "selection = [18,19,20,21]\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "xgb.fit(train_features[:25000,selection],train_true_labels[:25000])\n",
    "preds_xgb = xgb.predict(train_features[25000:30000,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,train_true_labels[25000:30000])), list(map(int,preds_xgb)))\n",
    "f1 = metrics.f1_score(list(map(int,train_true_labels[25000:30000])), list(map(int,preds_xgb)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = list(preds_xgb)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_xgb = list(zip(range(len(competition_set)), preds_xgb))\n",
    "\n",
    "with open(\"xgb_predictions.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_xgb:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5fe441d8fb56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcombined_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_test_svm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_lg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_knn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_et\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_xgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_true_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpreds_joined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#### NEEDS TO BE FIXED\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_et = np.reshape(preds_extra,(len(preds_extra),1))\n",
    "preds_test_xgb = np.reshape(preds_xgb,(len(preds_xgb),1))\n",
    "\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_et,preds_test_xgb],axis=1)\n",
    "\n",
    "VotingClassifier.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = VotingClassifier.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "# tuned_parameters = [{'penalty': ['l1'], 'C': [1, 10], 'loss': ['squared_hinge'],'dual': [False],\n",
    "#                      'max_iter': [1000,5000]}]\n",
    "tuned_parameters = [{'n_estimators': [500],'criterion': ['gini'],'max_depth': [None,50,100],\n",
    "                    'min_samples_split': [2,10], 'min_samples_leaf': [4,0.00001], 'bootstrap': [True, False]}]\n",
    "selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "\n",
    "scores = ['f1_macro'] #'accuracy_score'\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(ExtraTreesClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = test_true_labels, clf.predict(test_features[:,selection])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = ...\n",
    "splitter = ['best', 'random']\n",
    "max_depth =  [int(x) for x in np.linspace(1, 110, num = 15)].append([None])\n",
    "min_weight_fraction_leaf = [0, 0.00001, 0.000001]\n",
    "max_features = [None, 'sqrt', 'log2']\n",
    "max_leaf_nodes = [None, 10, 100, 1000]\n",
    "\n",
    "n_estimators = [10, 20, 50, 100, 200]\n",
    "learning_rate = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 65 candidates, totalling 130 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 130 out of 130 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid='warn', n_iter=65, n_jobs=-1,\n",
       "          param_distributions={'base_estimator': [DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features='sqrt', max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we...itter='best')], 'n_estimators': [50, 100, 200, 500, 750], 'learning_rate': [0.005, 0.01, 0.1, 0.05]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier()\n",
    "selection = [ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26]\n",
    "\n",
    "#n_estimators: 100\n",
    "#learning_rate: 0.01\n",
    "\n",
    "#max_depth = 5\n",
    "#min_samples_leaf = 1\n",
    "#min_samples_split = 2\n",
    "#min_weight_Fraction_leaf = 0\n",
    "\n",
    "\n",
    "base_estimator = [DecisionTreeClassifier(splitter = 'best', max_depth = 1, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 10), \n",
    "                 DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 50),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 10, min_weight_fraction_leaf = 0.00001, max_features = None, max_leaf_nodes = 10),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0.000001, max_features = 'sqrt', max_leaf_nodes = 100),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0, max_features = 'sqrt', max_leaf_nodes = 10),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 2, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 25),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0.00001, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0, max_features = 'sqrt', max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 10, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None)\n",
    "                 ]\n",
    "\n",
    "n_estimators = [ 50, 100, 200, 500, 750]\n",
    "learning_rate = [0.005, 0.01, 0.1, 0.05]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'base_estimator': base_estimator, \n",
    "              'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate}\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "ada_random = RandomizedSearchCV(estimator = adaBoost, param_distributions = random_grid, n_iter = 65,\n",
    "                              cv = 2, verbose = 10, random_state=42, n_jobs = -1)\n",
    "\n",
    "ada_random.fit(train_features_reduced[:,selection], train_true_labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.01, 0.01, 0.05, 0.05, 0.005, 0.05, 0.01, 0.05, 0.05]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "top = np.argsort(ada_random.cv_results_['rank_test_score'])\n",
    "# top[:5]\n",
    "# xgb_random.best_index_\n",
    "# mode([rf_random.cv_results_['params'][i]['bootstrap'] for i in top[:15]])\n",
    "[ada_random.cv_results_['params'][i]['learning_rate'] for i in top[:10]]\n",
    "#n_estimators: 750\n",
    "#learning_rate: 0.01\n",
    "\n",
    "#max_depth = 4\n",
    "#min_samples_leaf = 1\n",
    "#min_samples_split = 2\n",
    "#min_weight_Fraction_leaf = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(range(27,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50\n",
      "1 / 50\n",
      "2 / 50\n",
      "3 / 50\n",
      "4 / 50\n",
      "5 / 50\n",
      "6 / 50\n",
      "7 / 50\n",
      "8 / 50\n",
      "9 / 50\n",
      "10 / 50\n",
      "11 / 50\n",
      "12 / 50\n",
      "13 / 50\n",
      "14 / 50\n",
      "15 / 50\n",
      "16 / 50\n",
      "17 / 50\n",
      "18 / 50\n",
      "19 / 50\n",
      "20 / 50\n",
      "21 / 50\n",
      "22 / 50\n",
      "23 / 50\n",
      "24 / 50\n",
      "25 / 50\n",
      "26 / 50\n",
      "27 / 50\n",
      "28 / 50\n",
      "29 / 50\n",
      "30 / 50\n",
      "31 / 50\n",
      "32 / 50\n",
      "33 / 50\n",
      "34 / 50\n",
      "35 / 50\n",
      "36 / 50\n",
      "37 / 50\n",
      "38 / 50\n",
      "39 / 50\n",
      "40 / 50\n",
      "41 / 50\n",
      "42 / 50\n",
      "43 / 50\n",
      "44 / 50\n",
      "45 / 50\n",
      "46 / 50\n",
      "47 / 50\n",
      "48 / 50\n",
      "49 / 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.89805278, 1.79589894, 1.        , 1.78291101,\n",
       "       1.        , 1.87606643, 1.        , 1.        , 1.83137194,\n",
       "       1.        , 1.90559243, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.92520885, 1.93640245, 1.        , 1.        ,\n",
       "       1.93564076, 1.93544767, 1.8534672 , 1.9270696 , 1.9209067 ,\n",
       "       1.91657448, 1.82074365, 1.80740913, 1.        , 1.00834313,\n",
       "       1.0032723 , 1.        , 1.00834313, 1.        , 1.00504387,\n",
       "       1.        , 1.03667017, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.78414592, 1.        ,\n",
       "       1.00625022, 1.        , 1.        , 1.        , 1.00049745,\n",
       "       1.00040459, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.00696388, 1.        , 1.9463327 , 1.        , 1.        ,\n",
       "       1.        , 1.0042149 , 1.        , 1.        , 1.        ,\n",
       "       1.00142482, 1.        , 1.00464836, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.00688077, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.86308314,\n",
       "       1.        , 1.00159776, 1.00159776, 1.06094796, 1.08603222,\n",
       "       1.        , 1.00696388, 1.00191304, 1.        , 1.        ,\n",
       "       1.92708286, 1.00531596, 1.        , 1.        , 1.00003107,\n",
       "       1.        , 1.00308204, 1.94044491, 1.0087655 , 1.00183555,\n",
       "       1.00618592, 1.00003107, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.0042149 , 1.01248941, 1.        , 1.00038791,\n",
       "       1.01248941, 1.04370495, 1.        , 1.        , 1.        ,\n",
       "       1.00183555, 1.        , 1.        , 1.00142482, 1.00191304,\n",
       "       1.00142723, 1.        , 1.00038791, 1.03392059, 1.        ,\n",
       "       1.0076386 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.00541057, 1.08497141,\n",
       "       1.06094796, 1.00026421, 1.        , 1.02685504, 1.        ,\n",
       "       1.        , 1.        , 1.00308204, 1.        , 1.01899156,\n",
       "       1.        , 1.        , 1.08197779])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr \n",
    "\n",
    "classifier = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "weights = WRANDSEARCH(classifier, train_sp[:60000], train_true_labels[:60000], [1,  2,  4,  6,  9, 11, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27], \n",
    "                      num_features = 21, iterations = 50)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25,\n",
       "        26]),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(selector.ranking_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 10\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-81b8a572d786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkdtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "(ms,cc) = pw.by_chunk(training_set[:10000],train_graph,kdtree,l,node_dict,index_dict)\n",
    "t1 = time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 94\n",
      "20 / 94\n",
      "40 / 94\n",
      "60 / 94\n",
      "80 / 94\n"
     ]
    }
   ],
   "source": [
    "competition_paths_dict = prep.all_paths(competition_set,train_graph,pairs_subset_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './features_train/'+'max_sim'+'_reducedgraph'\n",
    "try:\n",
    "    this_feat = read_feature(file_path)\n",
    "except:\n",
    "    print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
