{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_pairwise' from '/home/jacob/JUPYTER PROJECTS/ML/project/features_pairwise.py'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(prep)\n",
    "importlib.reload(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 27770, n_features: 2890\n",
      "n_samples: 27770, n_features: 10000\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 16%\n",
      "n_samples: 27770, n_features: 150000\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 7%\n"
     ]
    }
   ],
   "source": [
    "import features_nodewise as nw\n",
    "import features_pairwise as pw\n",
    "import preprocessing as prep\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import igraph\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "from functools import reduce\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pickle\n",
    "\n",
    "## Read train / test node pairs\n",
    "# nltk.download('punkt') # for tokenization\n",
    "# nltk.download('stopwords')\n",
    "# stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "# stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"./data/train_train_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "with open(\"./data/train_test_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "    \n",
    "with open(\"./data/testing_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    competition_set  = list(reader)\n",
    "    \n",
    "competition_set = [element[0].split(\" \") for element in competition_set]\n",
    "\n",
    "random.seed(0)\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "to_keep_train = random.sample( range(len(training_set)),k=int(round(len(training_set)*0.05)) )\n",
    "training_set_reduced = [training_set[i] for i in to_keep_train]\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "to_keep_test = random.sample( range(len(testing_set)),k=int(round(len(testing_set)*1)) )\n",
    "testing_set_reduced = [testing_set[i] for i in to_keep_test]\n",
    "\n",
    "with open(\"./data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "corpus = [element[5] for element in node_info]\n",
    "titles = [element[2] for element in node_info]\n",
    "\n",
    "t_titles = prep.tfidf(titles)\n",
    "t = prep.tfidf(corpus)\n",
    "l = nw.LSA(t,n_components=100)\n",
    "\n",
    "t_ngrams = prep.tfidf(corpus, r= (2,3), midf = 2, madf=0.5,feats=150000, sublinear = True)\n",
    "l_ngrams = nw.LSA(t_ngrams,n_components=300)\n",
    "\n",
    "kdtree = nw.KDTree(l)\n",
    "kdtree_n = nw.KDTree(l_ngrams)\n",
    "\n",
    "IDs = [element[0] for element in node_info]\n",
    "node_dict = prep.to_dict( [element[0] for element in node_info],range(len(node_info)) )\n",
    "index_dict = prep.to_dict(range(len(IDs)),IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_sim = t_titles*t_titles.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# create graphs (train vs test), (reduced vs full)\n",
    "# for some reason np.mean([nw.node_degree(t[0],gold_train_graph) for t in random.sample(training_set,10000)]) is less than mean for competition graph?\n",
    "\n",
    "train_IDs = np.array(node_info)[:,0] \n",
    "# train_edges = [(element[0],element[1]) for element in training_set]\n",
    "# train_graph = prep.article_graph(train_IDs,train_edges)\n",
    "train_edges = [(element[0],element[1]) for element in training_set if element[2]=='1']\n",
    "train_graph = prep.article_graph(train_IDs,train_edges)\n",
    "\n",
    "#test graph is train graph\n",
    "# test_IDs = train_IDs\n",
    "# test_edges = train_edges\n",
    "# test_graph = prep.article_graph(test_IDs,test_edges)\n",
    "\n",
    "competition_IDs = train_IDs\n",
    "competition_edges = train_edges\n",
    "competition_edges.extend([(element[0],element[1]) for element in testing_set if element[2]=='1'])\n",
    "competition_graph = prep.article_graph(competition_IDs,competition_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "## Read all the features that we have stored in files\n",
    "import os.path\n",
    "\n",
    "def to_feature_shape(feat):\n",
    "    feat = np.array(feat)\n",
    "    if len(feat.shape) == 1:#not a real array but just a long list\n",
    "        feat = np.reshape(feat,(feat.shape[0],1))\n",
    "    return feat\n",
    "\n",
    "#This method should throw an error if something goes wrong\n",
    "def read_feature(file_path):\n",
    "    f = open(file_path, 'rb')\n",
    "    feat = to_feature_shape(pickle.load(f))\n",
    "    f.close()\n",
    "    return feat\n",
    "    \n",
    "features_to_read = [\"overlap_title\",\n",
    "                    \"comm_auth\",\n",
    "                    \"temp_diff\",\n",
    "                    \"edge_check\",\n",
    "                    \"LSA_distance\",\n",
    "                    \"title_sim\",\n",
    "                    \"N_LSA_distance\",\n",
    "                    \"citation_check\",\n",
    "                    \"max_sim\",\n",
    "                    \"peer_popularity\",\n",
    "                    \"temporal_fit\",\n",
    "                    \"succ_pred\",\n",
    "                    \"node_degree\",\n",
    "                   \"path_length\"]\n",
    "\n",
    "\n",
    "\n",
    "train_features_dict = dict()\n",
    "train_features_reduced_dict = dict()\n",
    "test_features_dict = dict()\n",
    "competition_features_dict = dict()\n",
    "\n",
    "for name in features_to_read:\n",
    "    # Train\n",
    "    loaded = False\n",
    "    file_path = './features_train/'+name+'_goldgraphfixed'\n",
    "#     if name != 'edge_check' and name!='max_sim' and name!='succ_pred' and name!='citation_check':\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        train_features_dict[name] = this_feat\n",
    "        train_features_reduced_dict[name] = this_feat[to_keep_train,:]\n",
    "        loaded = True\n",
    "        print(1)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    if loaded==False:\n",
    "        # Train reduced\n",
    "        file_path = './features_train/'+name+'_reducedgraph'\n",
    "        try:\n",
    "            this_feat = read_feature(file_path)\n",
    "            train_features_dict[name] = this_feat\n",
    "            train_features_reduced_dict[name] = this_feat[to_keep_train,:]\n",
    "            loaded = True\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if loaded==False:\n",
    "        # Train reduced\n",
    "        file_path = './features_train/'+name\n",
    "        try:\n",
    "            this_feat = read_feature(file_path)\n",
    "            train_features_dict[name] = this_feat\n",
    "            train_features_reduced_dict[name] = this_feat[to_keep_train,:]\n",
    "            loaded = True\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    loaded = False\n",
    "    # Test\n",
    "#     if name != 'edge_check' and name!='max_sim' and name!='succ_pred' and name!='citation_check':\n",
    "    file_path = './features_test/'+name+'_goldgraphfixed'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        test_features_dict[name] = this_feat\n",
    "        loaded = True\n",
    "        print(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if loaded == False:\n",
    "        # Test reduced\n",
    "        file_path = './features_test/'+name+'_reducedgraph'\n",
    "        try:\n",
    "            this_feat = read_feature(file_path)\n",
    "            test_features_dict[name] = this_feat\n",
    "            loaded = True\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if loaded == False:\n",
    "        # Test reduced\n",
    "        file_path = './features_test/'+name\n",
    "        try:\n",
    "            this_feat = read_feature(file_path)\n",
    "            test_features_dict[name] = this_feat\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    \n",
    "    file_path = './features_competition/'+name\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        competition_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass\n",
    "    # Test reduced\n",
    "    file_path = './features_competition/'+name+'_reducedgraph'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        competition_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    file_path = './features_competition/'+name+'_goldgraphfixed'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        competition_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(train_true_labels,(train_true_labels.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "train_true_labels = read_feature('./features_train/true_labels')\n",
    "train_true_labels = np.reshape(train_true_labels,(train_true_labels.shape[0],))\n",
    "train_true_labels_reduced = train_true_labels[to_keep_train]\n",
    "test_true_labels = read_feature('./features_test/true_labels')\n",
    "test_true_labels = np.reshape(test_true_labels,(test_true_labels.shape[0],))\n",
    "test_true_labels_reduced = test_true_labels[to_keep_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current wd:  /home/jacob/JUPYTER PROJECTS/ML/project\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "###   Write features to disk - Training  ###\n",
    "############################################\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def write_feature_to_disk(feat,file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(feat,file)\n",
    "\n",
    "print(\"Current wd: \",os.getcwd())\n",
    "# write_feature_to_disk(train_features_reduced_dict['title_sim'],'./features_train/title_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap_title (554602, 1)\n",
      "comm_auth (554602, 1)\n",
      "temp_diff (554602, 1)\n",
      "edge_check (554602, 1)\n",
      "LSA_distance (554602, 1)\n",
      "title_sim (554602, 1)\n",
      "N_LSA_distance (554602, 1)\n",
      "citation_check (554602, 4)\n",
      "max_sim (554602, 9)\n",
      "peer_popularity (554602, 1)\n",
      "temporal_fit (554602, 2)\n",
      "succ_pred (554602, 4)\n",
      "node_degree (554602, 4)\n",
      "path_length (554602, 1)\n"
     ]
    }
   ],
   "source": [
    "#Combine all features to one vector\n",
    "train_features_dict.keys()\n",
    "test_features_dict.keys()\n",
    "for key,feat in train_features_dict.items():\n",
    "    print(key,feat.shape)\n",
    "train_features = np.concatenate([train_features_dict['overlap_title'],\n",
    "                                         train_features_dict['comm_auth'],\n",
    "                                         train_features_dict['temp_diff'],\n",
    "                                         train_features_dict['citation_check'],\n",
    "                                         train_features_dict['max_sim'],\n",
    "                                         train_features_dict['peer_popularity'],\n",
    "                                         train_features_dict['edge_check'],\n",
    "                                         train_features_dict['succ_pred'],\n",
    "                                         train_features_dict['LSA_distance'],\n",
    "                                         train_features_dict['title_sim'],\n",
    "                                         train_features_dict['temporal_fit'],\n",
    "                                        train_features_dict['N_LSA_distance'],\n",
    "                                        train_features_dict['path_length'],\n",
    "                                        train_features_dict['node_degree']]                                            \n",
    "                                        ,axis = 1)\n",
    "\n",
    "train_features_reduced = np.concatenate([train_features_reduced_dict['overlap_title'],\n",
    "                                         train_features_reduced_dict['comm_auth'],\n",
    "                                         train_features_reduced_dict['temp_diff'],\n",
    "                                         train_features_reduced_dict['citation_check'],\n",
    "                                         train_features_reduced_dict['max_sim'],\n",
    "                                         train_features_reduced_dict['peer_popularity'],\n",
    "                                         train_features_reduced_dict['edge_check'],\n",
    "                                         train_features_reduced_dict['succ_pred'],\n",
    "                                         train_features_reduced_dict['LSA_distance'],\n",
    "                                         train_features_reduced_dict['title_sim'],\n",
    "                                         train_features_reduced_dict['temporal_fit'],\n",
    "                                        train_features_reduced_dict['N_LSA_distance'],\n",
    "                                        train_features_reduced_dict['path_length'],\n",
    "                                        train_features_reduced_dict['node_degree']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "test_features = np.concatenate(        [test_features_dict['overlap_title'],\n",
    "                                        test_features_dict['comm_auth'],\n",
    "                                        test_features_dict['temp_diff'],\n",
    "                                        test_features_dict['citation_check'],\n",
    "                                        test_features_dict['max_sim'],\n",
    "                                        test_features_dict['peer_popularity'],\n",
    "                                        test_features_dict['edge_check'],\n",
    "                                        test_features_dict['succ_pred'],\n",
    "                                        test_features_dict['LSA_distance'],\n",
    "                                        test_features_dict['title_sim'],\n",
    "                                        test_features_dict['temporal_fit'],\n",
    "                                       test_features_dict['N_LSA_distance'],\n",
    "                                       test_features_dict['path_length'],\n",
    "                                       test_features_dict['node_degree']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "\n",
    "competition_features = np.concatenate(  [competition_features_dict['overlap_title'],\n",
    "                                        competition_features_dict['comm_auth'],\n",
    "                                        competition_features_dict['temp_diff'],\n",
    "                                        competition_features_dict['citation_check'],\n",
    "                                        competition_features_dict['max_sim'],\n",
    "                                        competition_features_dict['peer_popularity'],\n",
    "                                        competition_features_dict['edge_check'],\n",
    "                                        competition_features_dict['succ_pred'],\n",
    "                                        competition_features_dict['LSA_distance'],\n",
    "                                        competition_features_dict['title_sim'],\n",
    "                                        competition_features_dict['temporal_fit'],\n",
    "                                        competition_features_dict['N_LSA_distance'],\n",
    "                                        competition_features_dict['path_length']]\n",
    "                                        ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "\n",
    "poly = PF(degree=2, interaction_only=False)\n",
    "\n",
    "selection = [1, 7, 9, 10, 11, 15, 16, 19, 21, 22, 23, 6, 25, 26, 27]\n",
    "# selection = list(range(train_features_reduced.shape[1]))\n",
    "\n",
    "train_sp = poly.fit_transform(train_features[:,selection])\n",
    "test_sp = poly.fit_transform(test_features[:,selection])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS()\n",
    "normalized_train_features_reduced = scaler.fit_transform(train_features_reduced)\n",
    "normalized_test_features = scaler.fit_transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554602, 32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9707108849121655 f1: 0.9728685707333395\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import copy\n",
    "\n",
    "classifier = svm.LinearSVC(loss='hinge')\n",
    "# selection = [23, 1, 16, 20, 22, 6, 21]\n",
    "selection = list(range(train_features_reduced.shape[1]))\n",
    "svm_s = copy.copy(selection)\n",
    "\n",
    "# classifier.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "# preds_svm = list(classifier.predict(test_features[:,selection]))\n",
    "classifier.fit(normalized_train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "svm_c = classifier\n",
    "preds_svm = list(classifier.predict(normalized_test_features[:,selection]))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9649333333333333 f1: 0.9672028931288191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr \n",
    "selection = [ 1,  7,  9, 10, 11, 15, 16, 19, 21, 22, 23]\n",
    "selection.extend([6,25,26,27])\n",
    "selection.append(31)\n",
    "lr_s = copy.copy(selection)\n",
    "# selection = [i for i in range(16)]\n",
    "# selection.extend([41,103,115])\n",
    "\n",
    "model = lr(penalty='l1').fit(train_features_reduced[:,selection], train_true_labels_reduced[:])\n",
    "lr_c = model\n",
    "preds_lg = list(model.predict(test_features[:,selection]))\n",
    "\n",
    "# model = lr(penalty='l1').fit(train_features_reduced, train_true_labels)\n",
    "# preds_lg = list(model.predict(test_features))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argsort(list(map(lambda x: abs(x),model.coef_)))[0][:14]\n",
    "# sorted(list(map(lambda x: abs(x),model.coef_))[0],reverse=True)\n",
    "[poly.powers_[i,:] for i in [31,28,9,17,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9581021178788376 f1: 0.9613848202396804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "selection = [1, 2, 6, 13, 16, 20, 21, 22]\n",
    "knn_s = copy.copy(selection)\n",
    "\n",
    "nNhbr = KNeighborsClassifier(n_neighbors=9,weights='distance')\n",
    "nNhbr.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "knn_c = nNhbr\n",
    "preds_knn = nNhbr.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9557872270563126 f1: 0.9595274951532184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# selection = [0, 1, 2, 8, 13, 16, 20, 22]\n",
    "selection = [ 0,  2,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22,23, 25, 26, 27]\n",
    "dt_s = copy.copy(selection)\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "dt_c = dTree\n",
    "\n",
    "preds_dt = dTree.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.50986568e-06, 0.00000000e+00, 0.00000000e+00],\n",
       "       [9.99997490e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       [9.43410527e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [9.24313612e-01, 1.00000000e+00, 1.00000000e+00],\n",
       "       [7.56863879e-02, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.concatenate((probs_lr.reshape(-1,1),probs_dt.reshape(-1,1)),axis=1)\n",
    "np.concatenate((test,probs_dt.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_svm = svm_c.decision_function(normalized_test_features[:,svm_s])\n",
    "probs_lr = lr_c.predict_proba(test_features[:,lr_s])[:,0]\n",
    "probs_knn = knn_c.predict_proba(test_features[:,knn_s])[:,0]\n",
    "all_probs = [probs_svm,probs_lr,probs_knn]\n",
    "\n",
    "probs_features = all_probs[0].reshape(-1,1)\n",
    "for i in range(1,len(all_probs)):\n",
    "    probs_features = np.concatenate((probs_features,all_probs[i].reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9712067292138467 f1: 0.9731976148888756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "joint_model = lr(penalty='l1').fit(probs_features[:30000,:], test_true_labels[:30000])\n",
    "preds_lg = list(joint_model.predict(probs_features[30000:,:]))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[30000:])), list(map(int,preds_lg)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[30000:])), list(map(int,preds_lg)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.970852428964253 f1: 0.9730234136409909\n"
     ]
    }
   ],
   "source": [
    "# Joined forces\n",
    "joined_DTree = DecisionTreeClassifier()\n",
    "\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_dt = np.reshape(preds_dt,(len(preds_dt),1))\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_dt],axis=1)\n",
    "\n",
    "joined_DTree.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = joined_DTree.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are important?\n",
    "# Histogram of the feature frequency for all selections that reached > 90% acc\n",
    "frequency = [0]*total_num_features\n",
    "\n",
    "num_good_preds = 0\n",
    "min_acc = 0.93\n",
    "for i,acc in enumerate(accs):\n",
    "    if acc > min_acc:\n",
    "        num_good_preds += 1\n",
    "        for f in feature_selections[i]:\n",
    "            frequency[f] += 1\n",
    "#frequency = [freq/num_good_preds for freq in frequency]\n",
    "print(\"\")\n",
    "print(\"number of classifiers: \",len(accs))\n",
    "print(\"number of accs >\",min_acc,\": \",sum([1 for acc in accs if acc > min_acc]))\n",
    "plt.figure()\n",
    "plt.bar(x=range(len(frequency)),height=frequency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9740436709899852 f1: 0.9761527670935336\n"
     ]
    }
   ],
   "source": [
    "# Adaboost DecisionTrees\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "selection =  [ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26]\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4, min_samples_leaf = 1, min_samples_split = 2),\n",
    "                         n_estimators=750,learning_rate=0.01)\n",
    "ada.fit(train_features[:100000,selection],train_true_labels[:100000])\n",
    "preds_ada = ada.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)\n",
    "#0.9761527670935336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9645706780495813 f1: 0.9675674050918271\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "#fiddle with n_estimators and min_samples_leaf\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "selection = [1, 2,  5,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "#add one to min_sample_leaf for full train_features (or change to 4)\n",
    "extraTrees = ExtraTreesClassifier(n_estimators=750,max_depth=90,min_samples_split=10,min_samples_leaf=0.00001)\n",
    "extraTrees.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_extra = extraTrees.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9724019044491873 f1: 0.9746398129290187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#f1: 0.96989, takes ~35 mins\n",
    "selection = [2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "\n",
    "randForest = RandomForestClassifier(n_estimators = 750, min_samples_split = 5, min_samples_leaf = 4, max_depth = 60)\n",
    "\n",
    "randForest.fit(train_features[:,selection],train_true_labels)\n",
    "preds_randForest = randForest.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[:])), list(map(int,preds_randForest)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[:])), list(map(int,preds_randForest)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
    "preds_randForest = randForest.predict(competition_features[:,selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = list(preds_randForest)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_rf = list(zip(range(len(competition_set)), preds_rf))\n",
    "\n",
    "with open(\"rf_predictions0.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_rf:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "# with open('random_forest_model', 'wb') as file:\n",
    "#         pickle.dump(randForest,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9716795271712363 f1: 0.9739366926040642\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "selection = [2,22, 23, 25, 26, 7, 15, 21, 10, 5, 6,  16, 19, 27, 28, 29, 30, 31]\n",
    "# selection = [i for i in range(16)]\n",
    "# selection.extend([ 95, 102])\n",
    "\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "xgb.fit(train_features[:100000,selection],train_true_labels[:100000])\n",
    "preds_xgb = xgb.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[:])), list(map(int,preds_xgb)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[:])), list(map(int,preds_xgb)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9834 f1: 0.9846438482886217\n"
     ]
    }
   ],
   "source": [
    "selection = [0,2,7,8,9,13,16,19,20,21,22,23,24,25,26,27]\n",
    "selection = [18,19,20,21]\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "xgb.fit(train_features[:25000,selection],train_true_labels[:25000])\n",
    "preds_xgb = xgb.predict(train_features[25000:30000,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,train_true_labels[25000:30000])), list(map(int,preds_xgb)))\n",
    "f1 = metrics.f1_score(list(map(int,train_true_labels[25000:30000])), list(map(int,preds_xgb)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = list(preds_xgb)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_xgb = list(zip(range(len(competition_set)), preds_xgb))\n",
    "\n",
    "with open(\"xgb_predictions.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_xgb:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5fe441d8fb56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcombined_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_test_svm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_lg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_knn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_et\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_xgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_true_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpreds_joined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#### NEEDS TO BE FIXED\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_et = np.reshape(preds_extra,(len(preds_extra),1))\n",
    "preds_test_xgb = np.reshape(preds_xgb,(len(preds_xgb),1))\n",
    "\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_et,preds_test_xgb],axis=1)\n",
    "\n",
    "VotingClassifier.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = VotingClassifier.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "# tuned_parameters = [{'penalty': ['l1'], 'C': [1, 10], 'loss': ['squared_hinge'],'dual': [False],\n",
    "#                      'max_iter': [1000,5000]}]\n",
    "tuned_parameters = [{'n_estimators': [500],'criterion': ['gini'],'max_depth': [None,50,100],\n",
    "                    'min_samples_split': [2,10], 'min_samples_leaf': [4,0.00001], 'bootstrap': [True, False]}]\n",
    "selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "\n",
    "scores = ['f1_macro'] #'accuracy_score'\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(ExtraTreesClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = test_true_labels, clf.predict(test_features[:,selection])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = ...\n",
    "splitter = ['best', 'random']\n",
    "max_depth =  [int(x) for x in np.linspace(1, 110, num = 15)].append([None])\n",
    "min_weight_fraction_leaf = [0, 0.00001, 0.000001]\n",
    "max_features = [None, 'sqrt', 'log2']\n",
    "max_leaf_nodes = [None, 10, 100, 1000]\n",
    "\n",
    "n_estimators = [10, 20, 50, 100, 200]\n",
    "learning_rate = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 65 candidates, totalling 130 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 130 out of 130 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "          fit_params=None, iid='warn', n_iter=65, n_jobs=-1,\n",
       "          param_distributions={'base_estimator': [DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features='sqrt', max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we...itter='best')], 'n_estimators': [50, 100, 200, 500, 750], 'learning_rate': [0.005, 0.01, 0.1, 0.05]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "adaBoost = AdaBoostClassifier()\n",
    "selection = [ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26]\n",
    "\n",
    "#n_estimators: 100\n",
    "#learning_rate: 0.01\n",
    "\n",
    "#max_depth = 5\n",
    "#min_samples_leaf = 1\n",
    "#min_samples_split = 2\n",
    "#min_weight_Fraction_leaf = 0\n",
    "\n",
    "\n",
    "base_estimator = [DecisionTreeClassifier(splitter = 'best', max_depth = 1, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 10), \n",
    "                 DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 50),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 10, min_weight_fraction_leaf = 0.00001, max_features = None, max_leaf_nodes = 10),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0.000001, max_features = 'sqrt', max_leaf_nodes = 100),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0, max_features = 'sqrt', max_leaf_nodes = 10),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 2, min_weight_fraction_leaf = 0.00001, max_features = 'sqrt', max_leaf_nodes = 25),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0.00001, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 7, min_weight_fraction_leaf = 0, max_features = 'sqrt', max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 10, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None),\n",
    "                  DecisionTreeClassifier(splitter = 'best', max_depth = 4, min_weight_fraction_leaf = 0, max_features = None, max_leaf_nodes = None)\n",
    "                 ]\n",
    "\n",
    "n_estimators = [ 50, 100, 200, 500, 750]\n",
    "learning_rate = [0.005, 0.01, 0.1, 0.05]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'base_estimator': base_estimator, \n",
    "              'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate}\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "ada_random = RandomizedSearchCV(estimator = adaBoost, param_distributions = random_grid, n_iter = 65,\n",
    "                              cv = 2, verbose = 10, random_state=42, n_jobs = -1)\n",
    "\n",
    "ada_random.fit(train_features_reduced[:,selection], train_true_labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.01, 0.01, 0.05, 0.05, 0.005, 0.05, 0.01, 0.05, 0.05]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "top = np.argsort(ada_random.cv_results_['rank_test_score'])\n",
    "# top[:5]\n",
    "# xgb_random.best_index_\n",
    "# mode([rf_random.cv_results_['params'][i]['bootstrap'] for i in top[:15]])\n",
    "[ada_random.cv_results_['params'][i]['learning_rate'] for i in top[:10]]\n",
    "#n_estimators: 750\n",
    "#learning_rate: 0.01\n",
    "\n",
    "#max_depth = 4\n",
    "#min_samples_leaf = 1\n",
    "#min_samples_split = 2\n",
    "#min_weight_Fraction_leaf = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(range(27,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "selection = [ 1,  7,  9, 10, 11, 15, 16, 19, 21, 22, 23]\n",
    "selection.extend([6,25,26,27])\n",
    "\n",
    "#37,38,40: 0.966\n",
    "#42,43,50 .967\n",
    "#53,54,55\n",
    "#62,63,65\n",
    "#67,68,66\n",
    "#86,87,88\n",
    "#106-108\n",
    "def WRANDSEARCH(estimator, features, labels, baseline, num_features = 16, iterations = 50, \n",
    "                rate = 1.5, emp_avg = 0.968, emp_max = 0.975, emp_min = 0.96):\n",
    "    \n",
    "    cv0 = random.sample(range(len(features)),int(len(features)/2))\n",
    "    cv1 = list(set(range(len(features)))-set(cv0))\n",
    "    \n",
    "    weights = np.ones(features.shape[1])\n",
    "    tot_features = len(weights)\n",
    "    \n",
    "    #adjust weights so that by final iteration 50% of features selected are from high performing features and 50% are from the rest\n",
    "    #as it stands this does not work properly for the reduction of probability\n",
    "    cap = (num_features-len(baseline))/2\n",
    "    evals_per_feature = iterations*(num_features-len(baseline))/tot_features\n",
    "    alpha = rate*(cap-1)/evals_per_feature\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        if random.random()>0.5:\n",
    "            selection = baseline\n",
    "        else:\n",
    "            removed = [random.choice(baseline), random.choice(baseline)]\n",
    "            selection = [i for i in baseline if not i in removed]\n",
    "            \n",
    "        selection.extend(random.choices(range(27, features.shape[1]), weights = weights[27:], k = num_features-len(selection)))\n",
    "        \n",
    "        model = estimator.fit(features[cv0,:][:,selection],labels[cv0])\n",
    "        preds = model.predict(features[cv1,:][:,selection])\n",
    "        f1 = metrics.f1_score(list(map(int,labels[cv1])), list(map(int,preds)))\n",
    "        model = estimator.fit(features[cv1,:][:,selection],labels[cv1])\n",
    "        preds = model.predict(features[cv0,:][:,selection])\n",
    "        f1 = (metrics.f1_score(list(map(int,labels[cv1])), list(map(int,preds))) + f1)/2\n",
    "        \n",
    "        if i==0:\n",
    "            avg = 2*f1/3+emp_avg/3\n",
    "            \n",
    "        if f1-avg>0:\n",
    "            for j in selection:\n",
    "                weights[j] = weights[j]+alpha*(f1-avg)/(emp_max-avg)\n",
    "        else:\n",
    "            for j in selection:\n",
    "                weights[j] = weights[j]*(1-0.35*(avg-f1)/(avg-emp_min))\n",
    "            \n",
    "        avg = (avg*3+f1)/4\n",
    "        \n",
    "        print(i, '/', iterations)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50\n",
      "1 / 50\n",
      "2 / 50\n",
      "3 / 50\n",
      "4 / 50\n",
      "5 / 50\n",
      "6 / 50\n",
      "7 / 50\n",
      "8 / 50\n",
      "9 / 50\n",
      "10 / 50\n",
      "11 / 50\n",
      "12 / 50\n",
      "13 / 50\n",
      "14 / 50\n",
      "15 / 50\n",
      "16 / 50\n",
      "17 / 50\n",
      "18 / 50\n",
      "19 / 50\n",
      "20 / 50\n",
      "21 / 50\n",
      "22 / 50\n",
      "23 / 50\n",
      "24 / 50\n",
      "25 / 50\n",
      "26 / 50\n",
      "27 / 50\n",
      "28 / 50\n",
      "29 / 50\n",
      "30 / 50\n",
      "31 / 50\n",
      "32 / 50\n",
      "33 / 50\n",
      "34 / 50\n",
      "35 / 50\n",
      "36 / 50\n",
      "37 / 50\n",
      "38 / 50\n",
      "39 / 50\n",
      "40 / 50\n",
      "41 / 50\n",
      "42 / 50\n",
      "43 / 50\n",
      "44 / 50\n",
      "45 / 50\n",
      "46 / 50\n",
      "47 / 50\n",
      "48 / 50\n",
      "49 / 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.89805278, 1.79589894, 1.        , 1.78291101,\n",
       "       1.        , 1.87606643, 1.        , 1.        , 1.83137194,\n",
       "       1.        , 1.90559243, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.92520885, 1.93640245, 1.        , 1.        ,\n",
       "       1.93564076, 1.93544767, 1.8534672 , 1.9270696 , 1.9209067 ,\n",
       "       1.91657448, 1.82074365, 1.80740913, 1.        , 1.00834313,\n",
       "       1.0032723 , 1.        , 1.00834313, 1.        , 1.00504387,\n",
       "       1.        , 1.03667017, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.78414592, 1.        ,\n",
       "       1.00625022, 1.        , 1.        , 1.        , 1.00049745,\n",
       "       1.00040459, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.00696388, 1.        , 1.9463327 , 1.        , 1.        ,\n",
       "       1.        , 1.0042149 , 1.        , 1.        , 1.        ,\n",
       "       1.00142482, 1.        , 1.00464836, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.00688077, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.86308314,\n",
       "       1.        , 1.00159776, 1.00159776, 1.06094796, 1.08603222,\n",
       "       1.        , 1.00696388, 1.00191304, 1.        , 1.        ,\n",
       "       1.92708286, 1.00531596, 1.        , 1.        , 1.00003107,\n",
       "       1.        , 1.00308204, 1.94044491, 1.0087655 , 1.00183555,\n",
       "       1.00618592, 1.00003107, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.0042149 , 1.01248941, 1.        , 1.00038791,\n",
       "       1.01248941, 1.04370495, 1.        , 1.        , 1.        ,\n",
       "       1.00183555, 1.        , 1.        , 1.00142482, 1.00191304,\n",
       "       1.00142723, 1.        , 1.00038791, 1.03392059, 1.        ,\n",
       "       1.0076386 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.00541057, 1.08497141,\n",
       "       1.06094796, 1.00026421, 1.        , 1.02685504, 1.        ,\n",
       "       1.        , 1.        , 1.00308204, 1.        , 1.01899156,\n",
       "       1.        , 1.        , 1.08197779])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr \n",
    "\n",
    "classifier = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "weights = WRANDSEARCH(classifier, train_sp[:60000], train_true_labels[:60000], [1,  2,  4,  6,  9, 11, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27], \n",
    "                      num_features = 21, iterations = 50)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(weights>1.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 12 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 1, 1, 2, 4, 3, 3, 4, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "estimator = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                    max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "selection = [2,22, 23, 25, 26, 7, 15, 21, 10, 5, 6,  16, 19, 27, 28, 29, 30, 31]\n",
    "# = ExtraTreesClassifier(n_estimators=500,max_depth=50,min_samples_split=10,min_samples_leaf=0.00001)\n",
    "# = DecisionTreeClassifier()\n",
    "# = lr(penalty='l1')\n",
    "# = svm.LinearSVC(loss='hinge',max_iter=10000)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "selector = RFECV(estimator, step=1, cv=2,min_features_to_select=3,verbose=10)\n",
    "selector = selector.fit(train_features[:50000,selection], train_true_labels[:50000])\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  4,  5,  6,  7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 25,\n",
       "        26]),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(selector.ranking_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_pairwise' from '/home/jacob/JUPYTER PROJECTS/ML/project/features_pairwise.py'>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 10\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-81b8a572d786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkdtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "(ms,cc) = pw.by_chunk(training_set[:10000],train_graph,kdtree,l,node_dict,index_dict)\n",
    "t1 = time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355.325560092926"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()-t0\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 94\n",
      "20 / 94\n",
      "40 / 94\n",
      "60 / 94\n",
      "80 / 94\n"
     ]
    }
   ],
   "source": [
    "competition_paths_dict = prep.all_paths(competition_set,train_graph,pairs_subset_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication_years = node_info_array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 555\n",
      "1 / 555\n",
      "2 / 555\n",
      "3 / 555\n",
      "4 / 555\n",
      "5 / 555\n",
      "6 / 555\n",
      "7 / 555\n",
      "8 / 555\n",
      "9 / 555\n",
      "10 / 555\n",
      "11 / 555\n",
      "12 / 555\n",
      "13 / 555\n",
      "14 / 555\n",
      "15 / 555\n",
      "16 / 555\n",
      "17 / 555\n",
      "18 / 555\n",
      "19 / 555\n",
      "20 / 555\n",
      "21 / 555\n",
      "22 / 555\n",
      "23 / 555\n",
      "24 / 555\n",
      "25 / 555\n",
      "26 / 555\n",
      "27 / 555\n",
      "28 / 555\n",
      "29 / 555\n",
      "30 / 555\n",
      "31 / 555\n",
      "32 / 555\n",
      "33 / 555\n",
      "34 / 555\n",
      "35 / 555\n",
      "36 / 555\n",
      "37 / 555\n",
      "38 / 555\n",
      "39 / 555\n",
      "40 / 555\n",
      "41 / 555\n",
      "42 / 555\n",
      "43 / 555\n",
      "44 / 555\n",
      "45 / 555\n",
      "46 / 555\n",
      "47 / 555\n",
      "48 / 555\n",
      "49 / 555\n",
      "50 / 555\n",
      "51 / 555\n",
      "52 / 555\n",
      "53 / 555\n",
      "54 / 555\n",
      "55 / 555\n",
      "56 / 555\n",
      "57 / 555\n",
      "58 / 555\n",
      "59 / 555\n",
      "60 / 555\n",
      "61 / 555\n",
      "62 / 555\n",
      "63 / 555\n",
      "64 / 555\n",
      "65 / 555\n",
      "66 / 555\n",
      "67 / 555\n",
      "68 / 555\n",
      "69 / 555\n",
      "70 / 555\n",
      "71 / 555\n",
      "72 / 555\n",
      "73 / 555\n",
      "74 / 555\n",
      "75 / 555\n",
      "76 / 555\n",
      "77 / 555\n",
      "78 / 555\n",
      "79 / 555\n",
      "80 / 555\n",
      "81 / 555\n",
      "82 / 555\n",
      "83 / 555\n",
      "84 / 555\n",
      "85 / 555\n",
      "86 / 555\n",
      "87 / 555\n",
      "88 / 555\n",
      "89 / 555\n",
      "90 / 555\n",
      "91 / 555\n",
      "92 / 555\n",
      "93 / 555\n",
      "94 / 555\n",
      "95 / 555\n",
      "96 / 555\n",
      "97 / 555\n",
      "98 / 555\n",
      "99 / 555\n",
      "100 / 555\n",
      "101 / 555\n",
      "102 / 555\n",
      "103 / 555\n",
      "104 / 555\n",
      "105 / 555\n",
      "106 / 555\n",
      "107 / 555\n",
      "108 / 555\n",
      "109 / 555\n",
      "110 / 555\n",
      "111 / 555\n",
      "112 / 555\n",
      "113 / 555\n",
      "114 / 555\n",
      "115 / 555\n",
      "116 / 555\n",
      "117 / 555\n",
      "118 / 555\n",
      "119 / 555\n",
      "120 / 555\n",
      "121 / 555\n",
      "122 / 555\n",
      "123 / 555\n",
      "124 / 555\n",
      "125 / 555\n",
      "126 / 555\n",
      "127 / 555\n",
      "128 / 555\n",
      "129 / 555\n",
      "130 / 555\n",
      "131 / 555\n",
      "132 / 555\n",
      "133 / 555\n",
      "134 / 555\n",
      "135 / 555\n",
      "136 / 555\n",
      "137 / 555\n",
      "138 / 555\n",
      "139 / 555\n",
      "140 / 555\n",
      "141 / 555\n",
      "142 / 555\n",
      "143 / 555\n",
      "144 / 555\n",
      "145 / 555\n",
      "146 / 555\n",
      "147 / 555\n",
      "148 / 555\n",
      "149 / 555\n",
      "150 / 555\n",
      "151 / 555\n",
      "152 / 555\n",
      "153 / 555\n",
      "154 / 555\n",
      "155 / 555\n",
      "156 / 555\n",
      "157 / 555\n",
      "158 / 555\n",
      "159 / 555\n",
      "160 / 555\n",
      "161 / 555\n",
      "162 / 555\n",
      "163 / 555\n",
      "164 / 555\n",
      "165 / 555\n",
      "166 / 555\n",
      "167 / 555\n",
      "168 / 555\n",
      "169 / 555\n",
      "170 / 555\n",
      "171 / 555\n",
      "172 / 555\n",
      "173 / 555\n",
      "174 / 555\n",
      "175 / 555\n",
      "176 / 555\n",
      "177 / 555\n",
      "178 / 555\n",
      "179 / 555\n",
      "180 / 555\n",
      "181 / 555\n",
      "182 / 555\n",
      "183 / 555\n",
      "184 / 555\n",
      "185 / 555\n",
      "186 / 555\n",
      "187 / 555\n",
      "188 / 555\n",
      "189 / 555\n",
      "190 / 555\n",
      "191 / 555\n",
      "192 / 555\n",
      "193 / 555\n",
      "194 / 555\n",
      "195 / 555\n",
      "196 / 555\n",
      "197 / 555\n",
      "198 / 555\n",
      "199 / 555\n",
      "200 / 555\n",
      "201 / 555\n",
      "202 / 555\n",
      "203 / 555\n",
      "204 / 555\n",
      "205 / 555\n",
      "206 / 555\n",
      "207 / 555\n",
      "208 / 555\n",
      "209 / 555\n",
      "210 / 555\n",
      "211 / 555\n",
      "212 / 555\n",
      "213 / 555\n",
      "214 / 555\n",
      "215 / 555\n",
      "216 / 555\n",
      "217 / 555\n",
      "218 / 555\n",
      "219 / 555\n",
      "220 / 555\n",
      "221 / 555\n",
      "222 / 555\n",
      "223 / 555\n",
      "224 / 555\n",
      "225 / 555\n",
      "226 / 555\n",
      "227 / 555\n",
      "228 / 555\n",
      "229 / 555\n",
      "230 / 555\n",
      "231 / 555\n",
      "232 / 555\n",
      "233 / 555\n",
      "234 / 555\n",
      "235 / 555\n",
      "236 / 555\n",
      "237 / 555\n",
      "238 / 555\n",
      "239 / 555\n",
      "240 / 555\n",
      "241 / 555\n",
      "242 / 555\n",
      "243 / 555\n",
      "244 / 555\n",
      "245 / 555\n",
      "246 / 555\n",
      "247 / 555\n",
      "248 / 555\n",
      "249 / 555\n",
      "250 / 555\n",
      "251 / 555\n",
      "252 / 555\n",
      "253 / 555\n",
      "254 / 555\n",
      "255 / 555\n",
      "256 / 555\n",
      "257 / 555\n",
      "258 / 555\n",
      "259 / 555\n",
      "260 / 555\n",
      "261 / 555\n",
      "262 / 555\n",
      "263 / 555\n",
      "264 / 555\n",
      "265 / 555\n",
      "266 / 555\n",
      "267 / 555\n",
      "268 / 555\n",
      "269 / 555\n",
      "270 / 555\n",
      "271 / 555\n",
      "272 / 555\n",
      "273 / 555\n",
      "274 / 555\n",
      "275 / 555\n",
      "276 / 555\n",
      "277 / 555\n",
      "278 / 555\n",
      "279 / 555\n",
      "280 / 555\n",
      "281 / 555\n",
      "282 / 555\n",
      "283 / 555\n",
      "284 / 555\n",
      "285 / 555\n",
      "286 / 555\n",
      "287 / 555\n",
      "288 / 555\n",
      "289 / 555\n",
      "290 / 555\n",
      "291 / 555\n",
      "292 / 555\n",
      "293 / 555\n",
      "294 / 555\n",
      "295 / 555\n",
      "296 / 555\n",
      "297 / 555\n",
      "298 / 555\n",
      "299 / 555\n",
      "300 / 555\n",
      "301 / 555\n",
      "302 / 555\n",
      "303 / 555\n",
      "304 / 555\n",
      "305 / 555\n",
      "306 / 555\n",
      "307 / 555\n",
      "308 / 555\n",
      "309 / 555\n",
      "310 / 555\n",
      "311 / 555\n",
      "312 / 555\n",
      "313 / 555\n",
      "314 / 555\n",
      "315 / 555\n",
      "316 / 555\n",
      "317 / 555\n",
      "318 / 555\n",
      "319 / 555\n",
      "320 / 555\n",
      "321 / 555\n",
      "322 / 555\n",
      "323 / 555\n",
      "324 / 555\n",
      "325 / 555\n",
      "326 / 555\n",
      "327 / 555\n",
      "328 / 555\n",
      "329 / 555\n",
      "330 / 555\n",
      "331 / 555\n",
      "332 / 555\n",
      "333 / 555\n",
      "334 / 555\n",
      "335 / 555\n",
      "336 / 555\n",
      "337 / 555\n",
      "338 / 555\n",
      "339 / 555\n",
      "340 / 555\n",
      "341 / 555\n",
      "342 / 555\n",
      "343 / 555\n",
      "344 / 555\n",
      "345 / 555\n",
      "346 / 555\n",
      "347 / 555\n",
      "348 / 555\n",
      "349 / 555\n",
      "350 / 555\n",
      "351 / 555\n",
      "352 / 555\n",
      "353 / 555\n",
      "354 / 555\n",
      "355 / 555\n",
      "356 / 555\n",
      "357 / 555\n",
      "358 / 555\n",
      "359 / 555\n",
      "360 / 555\n",
      "361 / 555\n",
      "362 / 555\n",
      "363 / 555\n",
      "364 / 555\n",
      "365 / 555\n",
      "366 / 555\n",
      "367 / 555\n",
      "368 / 555\n",
      "369 / 555\n",
      "370 / 555\n",
      "371 / 555\n",
      "372 / 555\n",
      "373 / 555\n",
      "374 / 555\n",
      "375 / 555\n",
      "376 / 555\n",
      "377 / 555\n",
      "378 / 555\n",
      "379 / 555\n",
      "380 / 555\n",
      "381 / 555\n",
      "382 / 555\n",
      "383 / 555\n",
      "384 / 555\n",
      "385 / 555\n",
      "386 / 555\n",
      "387 / 555\n",
      "388 / 555\n",
      "389 / 555\n",
      "390 / 555\n",
      "391 / 555\n",
      "392 / 555\n",
      "393 / 555\n",
      "394 / 555\n",
      "395 / 555\n",
      "396 / 555\n",
      "397 / 555\n",
      "398 / 555\n",
      "399 / 555\n",
      "400 / 555\n",
      "401 / 555\n",
      "402 / 555\n",
      "403 / 555\n",
      "404 / 555\n",
      "405 / 555\n",
      "406 / 555\n",
      "407 / 555\n",
      "408 / 555\n",
      "409 / 555\n",
      "410 / 555\n",
      "411 / 555\n",
      "412 / 555\n",
      "413 / 555\n",
      "414 / 555\n",
      "415 / 555\n",
      "416 / 555\n",
      "417 / 555\n",
      "418 / 555\n",
      "419 / 555\n",
      "420 / 555\n",
      "421 / 555\n",
      "422 / 555\n",
      "423 / 555\n",
      "424 / 555\n",
      "425 / 555\n",
      "426 / 555\n",
      "427 / 555\n",
      "428 / 555\n",
      "429 / 555\n",
      "430 / 555\n",
      "431 / 555\n",
      "432 / 555\n",
      "433 / 555\n",
      "434 / 555\n",
      "435 / 555\n",
      "436 / 555\n",
      "437 / 555\n",
      "438 / 555\n",
      "439 / 555\n",
      "440 / 555\n",
      "441 / 555\n",
      "442 / 555\n",
      "443 / 555\n",
      "444 / 555\n",
      "445 / 555\n",
      "446 / 555\n",
      "447 / 555\n",
      "448 / 555\n",
      "449 / 555\n",
      "450 / 555\n",
      "451 / 555\n",
      "452 / 555\n",
      "453 / 555\n",
      "454 / 555\n",
      "455 / 555\n",
      "456 / 555\n",
      "457 / 555\n",
      "458 / 555\n",
      "459 / 555\n",
      "460 / 555\n",
      "461 / 555\n",
      "462 / 555\n",
      "463 / 555\n",
      "464 / 555\n",
      "465 / 555\n",
      "466 / 555\n",
      "467 / 555\n",
      "468 / 555\n",
      "469 / 555\n",
      "470 / 555\n",
      "471 / 555\n",
      "472 / 555\n",
      "473 / 555\n",
      "474 / 555\n",
      "475 / 555\n",
      "476 / 555\n",
      "477 / 555\n",
      "478 / 555\n",
      "479 / 555\n",
      "480 / 555\n",
      "481 / 555\n",
      "482 / 555\n",
      "483 / 555\n",
      "484 / 555\n",
      "485 / 555\n",
      "486 / 555\n",
      "487 / 555\n",
      "488 / 555\n",
      "489 / 555\n",
      "490 / 555\n",
      "491 / 555\n",
      "492 / 555\n",
      "493 / 555\n",
      "494 / 555\n",
      "495 / 555\n",
      "496 / 555\n",
      "497 / 555\n",
      "498 / 555\n",
      "499 / 555\n",
      "500 / 555\n",
      "501 / 555\n",
      "502 / 555\n",
      "503 / 555\n",
      "504 / 555\n",
      "505 / 555\n",
      "506 / 555\n",
      "507 / 555\n",
      "508 / 555\n",
      "509 / 555\n",
      "510 / 555\n",
      "511 / 555\n",
      "512 / 555\n",
      "513 / 555\n",
      "514 / 555\n",
      "515 / 555\n",
      "516 / 555\n",
      "517 / 555\n",
      "518 / 555\n",
      "519 / 555\n",
      "520 / 555\n",
      "521 / 555\n",
      "522 / 555\n",
      "523 / 555\n",
      "524 / 555\n",
      "525 / 555\n",
      "526 / 555\n",
      "527 / 555\n",
      "528 / 555\n",
      "529 / 555\n",
      "530 / 555\n",
      "531 / 555\n",
      "532 / 555\n",
      "533 / 555\n",
      "534 / 555\n",
      "535 / 555\n",
      "536 / 555\n",
      "537 / 555\n",
      "538 / 555\n",
      "539 / 555\n",
      "540 / 555\n",
      "541 / 555\n",
      "542 / 555\n",
      "543 / 555\n",
      "544 / 555\n",
      "545 / 555\n",
      "546 / 555\n",
      "547 / 555\n",
      "548 / 555\n",
      "549 / 555\n",
      "550 / 555\n",
      "551 / 555\n",
      "552 / 555\n",
      "553 / 555\n",
      "554 / 555\n",
      "node_degree 554602\n",
      "0 / 61\n",
      "1 / 61\n",
      "2 / 61\n",
      "3 / 61\n",
      "4 / 61\n",
      "5 / 61\n",
      "6 / 61\n",
      "7 / 61\n",
      "8 / 61\n",
      "9 / 61\n",
      "10 / 61\n",
      "11 / 61\n",
      "12 / 61\n",
      "13 / 61\n",
      "14 / 61\n",
      "15 / 61\n",
      "16 / 61\n",
      "17 / 61\n",
      "18 / 61\n",
      "19 / 61\n",
      "20 / 61\n",
      "21 / 61\n",
      "22 / 61\n",
      "23 / 61\n",
      "24 / 61\n",
      "25 / 61\n",
      "26 / 61\n",
      "27 / 61\n",
      "28 / 61\n",
      "29 / 61\n",
      "30 / 61\n",
      "31 / 61\n",
      "32 / 61\n",
      "33 / 61\n",
      "34 / 61\n",
      "35 / 61\n",
      "36 / 61\n",
      "37 / 61\n",
      "38 / 61\n",
      "39 / 61\n",
      "40 / 61\n",
      "41 / 61\n",
      "42 / 61\n",
      "43 / 61\n",
      "44 / 61\n",
      "45 / 61\n",
      "46 / 61\n",
      "47 / 61\n",
      "48 / 61\n",
      "49 / 61\n",
      "50 / 61\n",
      "51 / 61\n",
      "52 / 61\n",
      "53 / 61\n",
      "54 / 61\n",
      "55 / 61\n",
      "56 / 61\n",
      "57 / 61\n",
      "58 / 61\n",
      "59 / 61\n",
      "60 / 61\n",
      "node_degree 60910\n"
     ]
    }
   ],
   "source": [
    "features_to_create = ['node_degree']\n",
    "insert_features_dict = dict()\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = training_set\n",
    "\n",
    "\n",
    "sp,ms,cc,nd = pw.by_chunk(training_set,train_graph, kdtree,l,node_dict,index_dict, pairs_subset_edges=True, chunk_size=1000,\n",
    "                          to_do = {'succ_pred':False, 'Max_Sim':False, 'Citation_Check':False, 'node_degree':True}, k_cc=500, metric_ms='COS', n_ms=3)\n",
    "insert_features_dict['node_degree'].extend(nd)\n",
    "        \n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "    \n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_train/'+feat+'_goldgraphfixed')\n",
    "\n",
    "features_to_create = ['node_degree']\n",
    "insert_features_dict = dict()\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = testing_set\n",
    "\n",
    "sp,ms,cc,nd = pw.by_chunk(testing_set,train_graph, kdtree,l,node_dict,index_dict, pairs_subset_edges=False, chunk_size=1000,\n",
    "                          to_do = {'succ_pred':False, 'Max_Sim':False, 'Citation_Check':False, 'node_degree':True}, k_cc=500, metric_ms='COS', n_ms=3)\n",
    "insert_features_dict['node_degree'].extend(nd)\n",
    "        \n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "    \n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_test/'+feat+'_goldgraphfixed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 554602\n",
      "100 / 554602\n",
      "200 / 554602\n",
      "300 / 554602\n",
      "400 / 554602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8216f043102e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m#     insert_features_dict[\"node_degree\"].append(degree)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0msucc_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msucc_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0minsert_features_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"succ_pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msucc_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JUPYTER PROJECTS/ML/project/features_pairwise.py\u001b[0m in \u001b[0;36msucc_pred\u001b[0;34m(source_ID, target_ID, graph)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeleted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mdeleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, source, target, **kwds)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36madd_edges\u001b[0;34m(self, es)\u001b[0m\n\u001b[1;32m    253\u001b[0m           \u001b[0mendpoints\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mVertices\u001b[0m \u001b[0mare\u001b[0m \u001b[0menumerated\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGraphBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_vertex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################################\n",
    "###  Construct features on TRAINING_SET  ###\n",
    "############################################\n",
    "\n",
    "\n",
    "train_true_labels = []\n",
    "features_to_create = ['succ_pred']\n",
    "#'peer_popularity', 'max_sim', 'edge_check', 'title_sim', 'citation_check', 'node_degree','succ_pred', 'N_LSA_distance'\n",
    "    \n",
    "# Where to insert created features\n",
    "insert_features_dict = train_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = training_set\n",
    "title_sim_ones = []\n",
    "title_sim_zeros = []\n",
    "\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "#     source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "#     source_title = [token for token in source_title if token not in stpwds]\n",
    "#     source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "#     target_title = target_info[2].lower().split(\" \")\n",
    "#     target_title = [token for token in target_title if token not in stpwds]\n",
    "#     target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "#     source_auth = source_info[3].split(\",\")\n",
    "#     target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    #overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    #insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    #temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    #insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    #comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    #insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,train_graph,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,train_graph)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "    #LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    #insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     title_weighted = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "#     if(int(triple[2]) == 0):\n",
    "#         title_sim_zeros.append(title_weighted)\n",
    "#     else:\n",
    "#         title_sim_ones.append(title_weighted)\n",
    "#     citation_check = pw.Citation_Check(source,target,kdtree,l,train_graph,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "\n",
    "#     degree = pw.node_degree(source,target,train_graph)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "\n",
    "    succ_pred = pw.succ_pred(source,target,train_graph)\n",
    "    insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "#     N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "#     insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "#     temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "#     insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "#     path_length = pw.path_length(source, target, training_paths_dict)\n",
    "#     insert_features_dict[\"path_length\"].append(path_length)\n",
    "    \n",
    "#     train_true_labels.append(triple[2])\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "    \n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_train/'+feat+'_goldgraphfixed')\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_train = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# train_true_labels = np.array(train_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './features_train/'+'max_sim'+'_reducedgraph'\n",
    "try:\n",
    "    this_feat = read_feature(file_path)\n",
    "except:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 175\n",
      "20 / 175\n",
      "40 / 175\n",
      "60 / 175\n",
      "80 / 175\n",
      "100 / 175\n",
      "120 / 175\n",
      "140 / 175\n",
      "160 / 175\n"
     ]
    }
   ],
   "source": [
    "testing_paths_dict = prep.all_paths(testing_set,train_graph,pairs_subset_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 60910\n",
      "1000 / 60910\n",
      "2000 / 60910\n",
      "3000 / 60910\n",
      "4000 / 60910\n",
      "5000 / 60910\n",
      "6000 / 60910\n",
      "7000 / 60910\n",
      "8000 / 60910\n",
      "9000 / 60910\n",
      "10000 / 60910\n",
      "11000 / 60910\n",
      "12000 / 60910\n",
      "13000 / 60910\n",
      "14000 / 60910\n",
      "15000 / 60910\n",
      "16000 / 60910\n",
      "17000 / 60910\n",
      "18000 / 60910\n",
      "19000 / 60910\n",
      "20000 / 60910\n",
      "21000 / 60910\n",
      "22000 / 60910\n",
      "23000 / 60910\n",
      "24000 / 60910\n",
      "25000 / 60910\n",
      "26000 / 60910\n",
      "27000 / 60910\n",
      "28000 / 60910\n",
      "29000 / 60910\n",
      "30000 / 60910\n",
      "31000 / 60910\n",
      "32000 / 60910\n",
      "33000 / 60910\n",
      "34000 / 60910\n",
      "35000 / 60910\n",
      "36000 / 60910\n",
      "37000 / 60910\n",
      "38000 / 60910\n",
      "39000 / 60910\n",
      "40000 / 60910\n",
      "41000 / 60910\n",
      "42000 / 60910\n",
      "43000 / 60910\n",
      "44000 / 60910\n",
      "45000 / 60910\n",
      "46000 / 60910\n",
      "47000 / 60910\n",
      "48000 / 60910\n",
      "49000 / 60910\n",
      "50000 / 60910\n",
      "51000 / 60910\n",
      "52000 / 60910\n",
      "53000 / 60910\n",
      "54000 / 60910\n",
      "55000 / 60910\n",
      "56000 / 60910\n",
      "57000 / 60910\n",
      "58000 / 60910\n",
      "59000 / 60910\n",
      "60000 / 60910\n",
      "succ_pred 60910\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "###  Construct features on TESTING_SET  ###\n",
    "###########################################\n",
    "\n",
    "features_to_create = ['succ_pred']\n",
    "#'peer_popularity', 'max_sim', 'edge_check', 'title_sim', 'citation_check','node_degree','succ_pred','N_LSA_distance'\n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = test_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = testing_set\n",
    "\n",
    "test_true_labels = []\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "#     source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "#     source_title = [token for token in source_title if token not in stpwds]\n",
    "#     source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "#     target_title = target_info[2].lower().split(\" \")\n",
    "#     target_title = [token for token in target_title if token not in stpwds]\n",
    "#     target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "#     source_auth = source_info[3].split(\",\")\n",
    "#     target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    #overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    #insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    #temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    #insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    #comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    #insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(train_graph,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,train_graph,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,train_graph)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "    #LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    #insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     title_weighted = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "    \n",
    "#     citation_check = pw.Citation_Check(source,target,kdtree,l,train_graph,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "    \n",
    "    succ_pred = pw.succ_pred(source,target,train_graph)\n",
    "    insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "#     degree = pw.node_degree(source,target,train_graph)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "    \n",
    "#     N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "#     insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "#     temporal_fit = pw.temp_fit(source,target,train_graph,node_dict,publication_years)\n",
    "#     insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "#     path_length = pw.path_length(source, target, testing_paths_dict)\n",
    "#     insert_features_dict[\"path_length\"].append(path_length)\n",
    "    \n",
    "#     test_true_labels.append(triple[2])\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_test = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# test_true_labels = np.array(test_true_labels)\n",
    "\n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_test/'+feat+'_goldgraphfixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap_title 32648\n",
      "comm_auth 32648\n",
      "temp_diff 32648\n",
      "edge_check 32648\n",
      "LSA_distance 32648\n",
      "title_sim 32648\n",
      "N_LSA_distance 32648\n",
      "citation_check 32648\n",
      "max_sim 32648\n",
      "peer_popularity 32648\n",
      "temporal_fit 32648\n",
      "succ_pred 32648\n",
      "node_degree 32648\n",
      "path_length 32648\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "###  Construct features on COMPETITION_SET  ###\n",
    "###########################################\n",
    "\n",
    "features_to_create = [\"path_length\"]\n",
    "# \"overlap_title\",\n",
    "#                  \"comm_auth\",\n",
    "#                  \"temp_diff\",\n",
    "#                 \"citation_check\",\n",
    "#                 \"max_sim\",\n",
    "#                 \"peer_popularity\",\n",
    "#                 \"edge_check\",\n",
    "#                 \"LSA_distance\",\n",
    "#                 \"node_degree\",\n",
    "#                 \"succ_pred\",\n",
    "#                 \"title_sim\",\n",
    "#                 \"temporal_fit\",\n",
    "#                 \"N_LSA_distance\",                 \n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = competition_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = competition_set\n",
    "\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "#     source_info = node_info[index_source]\n",
    "#     target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "#     source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "#     source_title = [token for token in source_title if token not in stpwds]\n",
    "#     source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "#     target_title = target_info[2].lower().split(\" \")\n",
    "#     target_title = [token for token in target_title if token not in stpwds]\n",
    "#     target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "#     source_auth = source_info[3].split(\",\")\n",
    "#     target_auth = target_info[3].split(\",\") \n",
    "\n",
    "# sp, ms, cc = pw.by_chunk(competition_set,train_graph, kdtree,l,node_dict,index_dict, pairs_subset_edges=False, chunk_size=1000, k_cc=500, metric_ms='COS', n_ms=3)\n",
    "# insert_features_dict['citation_check'].extend(cc)\n",
    "# insert_features_dict['max_sim'].extend(ms)\n",
    "# insert_features_dict['succ_pred'].extend(sp)\n",
    "    \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "#     overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "#     insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "#     temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "#     insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "#     comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "#     insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(competition_graph,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,competition_graph,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,competition_graph)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "#     LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "#     insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     citation_check = pw.Citation_Check(source,target,kdtree,l,competition_graph,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "    \n",
    "#     succ_pred = pw.succ_pred(source,target,competition_graph)\n",
    "#     insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "#     degree = pw.node_degree(source,target,competition_graph)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "    \n",
    "#     ts = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(ts)\n",
    "    \n",
    "#     temporal_fit = pw.temp_fit(source,target,competition_graph,node_dict,publication_years)\n",
    "#     insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    path_length = pw.path_length(source, target, competition_paths_dict)\n",
    "    insert_features_dict[\"path_length\"].append(path_length)\n",
    "    \n",
    "#     N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "#     insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "#     if i%1000==0:\n",
    "#         print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_test = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# test_true_labels = np.array(test_true_labels)\n",
    "\n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_competition/'+feat+'_goldgraphfixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_test/'+feat+'_goldgraphfixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_pairwise' from '/home/jacob/JUPYTER PROJECTS/ML/project/features_pairwise.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "importlib.reload(pw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
