{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_pairwise' from '/home/jacob/JUPYTER PROJECTS/ML/project/features_pairwise.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(prep)\n",
    "importlib.reload(pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jacob/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jacob/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "n_samples: 27770, n_features: 2890\n",
      "n_samples: 27770, n_features: 10000\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 16%\n",
      "n_samples: 27770, n_features: 150000\n",
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 7%\n"
     ]
    }
   ],
   "source": [
    "import features_nodewise as nw\n",
    "import features_pairwise as pw\n",
    "import preprocessing as prep\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import igraph\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "from functools import reduce\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pickle\n",
    "\n",
    "## Read train / test node pairs\n",
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "with open(\"./data/train_train_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "with open(\"./data/train_test_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_set  = list(reader)\n",
    "    \n",
    "with open(\"./data/testing_set.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    competition_set  = list(reader)\n",
    "    \n",
    "competition_set = [element[0].split(\" \") for element in competition_set]\n",
    "\n",
    "random.seed(0)\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "to_keep_train = random.sample( range(len(training_set)),k=int(round(len(training_set)*0.05)) )\n",
    "training_set_reduced = [training_set[i] for i in to_keep_train]\n",
    "\n",
    "testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "to_keep_test = random.sample( range(len(testing_set)),k=int(round(len(testing_set)*1)) )\n",
    "testing_set_reduced = [testing_set[i] for i in to_keep_test]\n",
    "\n",
    "with open(\"./data/node_information.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    node_info  = list(reader)\n",
    "\n",
    "corpus = [element[5] for element in node_info]\n",
    "titles = [element[2] for element in node_info]\n",
    "\n",
    "t_titles = prep.tfidf(titles)\n",
    "t = prep.tfidf(corpus)\n",
    "l = nw.LSA(t,n_components=100)\n",
    "\n",
    "t_ngrams = prep.tfidf(corpus, r= (2,3), midf = 2, madf=0.5,feats=150000, sublinear = True)\n",
    "l_ngrams = nw.LSA(t_ngrams,n_components=300)\n",
    "\n",
    "IDs = [element[0] for element in node_info]\n",
    "node_dict = prep.to_dict( [element[0] for element in node_info],range(len(node_info)) )\n",
    "index_dict = prep.to_dict(range(len(IDs)),IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_sim = t_titles*t_titles.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# create graphs (train vs test), (reduced vs full)\n",
    "\n",
    "train_IDs = set([training_set[i][0] for i in range(len(training_set))])\n",
    "train_IDs = train_IDs | set([training_set[i][1] for i in range(len(training_set))])\n",
    "train_IDs = list(train_IDs) #igraph doesn't like sets...\n",
    "train_edges = [(element[0],element[1]) for element in training_set]\n",
    "# train_graph = prep.article_graph(train_IDs,train_edges)\n",
    "\n",
    "train_IDs_reduced = set([training_set_reduced[i][0] for i in range(len(training_set_reduced))])\n",
    "train_IDs_reduced = train_IDs_reduced | set([training_set_reduced[i][1] for i in range(len(training_set_reduced))])\n",
    "train_IDs_reduced = list(train_IDs_reduced)\n",
    "train_edges_reduced = [(element[0],element[1]) for element in training_set_reduced]\n",
    "train_graph_reduced = prep.article_graph(train_IDs_reduced,train_edges_reduced)\n",
    "\n",
    "gold_train_graph_reduced = copy.copy(train_graph_reduced)\n",
    "to_del = [(element[0],element[1]) for element in training_set_reduced if element[2]=='0']\n",
    "gold_train_graph_reduced.delete_edges(to_del)\n",
    "\n",
    "test_IDs = set([testing_set[i][0] for i in range(len(testing_set))])\n",
    "test_IDs = test_IDs | set([testing_set[i][1] for i in range(len(testing_set))])\n",
    "test_IDs = list(test_IDs)\n",
    "test_edges = [(element[0],element[1]) for element in testing_set]\n",
    "# test_graph = prep.article_graph(test_IDs,test_edges)\n",
    "\n",
    "# all_IDs = set(test_IDs) | set(train_IDs)\n",
    "# all_IDs = list(all_IDs)\n",
    "# all_edges = train_edges\n",
    "# all_edges.extend(test_edges)\n",
    "# all_graph = prep.article_graph(all_IDs,all_edges)\n",
    "\n",
    "# test_IDs_reduced = set([testing_set_reduced[i][0] for i in range(len(testing_set_reduced))])\n",
    "# test_IDs_reduced = test_IDs_reduced | set([testing_set_reduced[i][1] for i in range(len(testing_set_reduced))])\n",
    "# test_IDs_reduced = list(test_IDs_reduced)\n",
    "# test_edges_reduced = [(element[0],element[1]) for element in testing_set_reduced]\n",
    "# test_graph_reduced = prep.article_graph(test_IDs_reduced,test_edges_reduced)\n",
    "\n",
    "competition_IDs = set([competition_set[i][0] for i in range(len(competition_set))])\n",
    "competition_IDs = competition_IDs | set([competition_set[i][1] for i in range(len(competition_set))])\n",
    "competition_IDs = set(competition_IDs) | set(test_IDs) | set(train_IDs) \n",
    "competition_IDs = list(competition_IDs)\n",
    "competition_edges = [(element[0],element[1]) for element in competition_set]\n",
    "competition_edges.extend(train_edges)\n",
    "competition_edges.extend(test_edges)\n",
    "competition_graph = prep.article_graph(competition_IDs,competition_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "competition_graph_reduced = copy.copy(competition_graph)\n",
    "to_rem = []\n",
    "for i,triple in enumerate(testing_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    if temp_diff<-1:\n",
    "        to_rem.append((source,target))\n",
    "        \n",
    "for i,triple in enumerate(training_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    if temp_diff<-1:\n",
    "        to_rem.append((source,target))\n",
    "    \n",
    "for i,triple in enumerate(competition_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    if temp_diff<-1:\n",
    "        to_rem.append((source,target))\n",
    "\n",
    "competition_graph_reduced.delete_edges(to_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.9333 2.2779\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for node in random.sample(train_IDs,10000):\n",
    "    l.append(train_graph.degree(node,mode='IN'))\n",
    "\n",
    "m=[]\n",
    "for node in random.sample(test_IDs,10000):\n",
    "    m.append(test_graph.degree(node,mode='IN'))\n",
    "print(np.mean(l), np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all the features that we have stored in files\n",
    "import os.path\n",
    "\n",
    "def to_feature_shape(feat):\n",
    "    feat = np.array(feat)\n",
    "    if len(feat.shape) == 1:#not a real array but just a long list\n",
    "        feat = np.reshape(feat,(feat.shape[0],1))\n",
    "    return feat\n",
    "\n",
    "#This method should throw an error if something goes wrong\n",
    "def read_feature(file_path):\n",
    "    f = open(file_path, 'rb')\n",
    "    feat = to_feature_shape(pickle.load(f))\n",
    "    f.close()\n",
    "    return feat\n",
    "    \n",
    "features_to_read = [\"overlap_title\",\n",
    "                 \"comm_auth\",\n",
    "                 \"temp_diff\",\n",
    "                \"citation_check\",\n",
    "                \"max_sim\",\n",
    "                \"peer_popularity\",\n",
    "                \"edge_check\",\n",
    "                \"LSA_distance\",\n",
    "                \"node_degree\",\n",
    "                \"succ_pred\",\n",
    "                \"title_sim\",\n",
    "                \"temporal_fit\",\n",
    "                   \"N_LSA_distance\"]\n",
    "\n",
    "train_features_dict = dict()\n",
    "train_features_reduced_dict = dict()\n",
    "test_features_dict = dict()\n",
    "competition_features_dict = dict()\n",
    "\n",
    "for name in features_to_read:\n",
    "    # Train\n",
    "    file_path = './current_features_train/'+name\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        train_features_dict[name] = this_feat\n",
    "        train_features_reduced_dict[name] = this_feat[to_keep_train,:]\n",
    "    except:\n",
    "        pass\n",
    "    # Train reduced\n",
    "    file_path = './current_features_train/'+name+'_reducedgraph'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        train_features_dict[name] = this_feat\n",
    "        train_features_reduced_dict[name] = this_feat[to_keep_train,:]\n",
    "    except:\n",
    "        pass\n",
    "    # Test\n",
    "    file_path = './current_features_test/'+name\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        test_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass\n",
    "    # Test reduced\n",
    "    file_path = './current_features_test/'+name+'_reducedgraph'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        test_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass\n",
    "    file_path = './features_competition/'+name\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        competition_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass\n",
    "    # Test reduced\n",
    "    file_path = './features_competition/'+name+'_reducedgraph'\n",
    "    try:\n",
    "        this_feat = read_feature(file_path)\n",
    "        competition_features_dict[name] = this_feat\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(train_true_labels,(train_true_labels.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "train_true_labels = read_feature('./features_train/true_labels')\n",
    "train_true_labels = np.reshape(train_true_labels,(train_true_labels.shape[0],))\n",
    "train_true_labels_reduced = train_true_labels[to_keep_train]\n",
    "test_true_labels = read_feature('./features_test/true_labels')\n",
    "test_true_labels = np.reshape(test_true_labels,(test_true_labels.shape[0],))\n",
    "test_true_labels_reduced = test_true_labels[to_keep_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current wd:  /home/jacob/JUPYTER PROJECTS/ML/project\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "###   Write features to disk - Training  ###\n",
    "############################################\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def write_feature_to_disk(feat,file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(feat,file)\n",
    "\n",
    "print(\"Current wd: \",os.getcwd())\n",
    "# write_feature_to_disk(train_features_reduced_dict['title_sim'],'./features_train/title_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "###   Write features to disk - Testing  ###\n",
    "###########################################\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"Current wd: \",os.getcwd())\n",
    "# write_feature_to_disk(test_features_dict['succ_pred'],'./features_test/succ_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap_title (554602, 1)\n",
      "comm_auth (554602, 1)\n",
      "temp_diff (554602, 1)\n",
      "citation_check (554602, 4)\n",
      "max_sim (554602, 9)\n",
      "peer_popularity (554602, 1)\n",
      "edge_check (554602, 1)\n",
      "LSA_distance (554602, 1)\n",
      "node_degree (554602, 4)\n",
      "succ_pred (554602, 4)\n",
      "title_sim (554602, 1)\n",
      "temporal_fit (554602, 2)\n",
      "N_LSA_distance (554602, 1)\n"
     ]
    }
   ],
   "source": [
    "#Combine all features to one vector\n",
    "train_features_dict.keys()\n",
    "test_features_dict.keys()\n",
    "for key,feat in train_features_dict.items():\n",
    "    print(key,feat.shape)\n",
    "train_features = np.concatenate([train_features_dict['overlap_title'],\n",
    "                                         train_features_dict['comm_auth'],\n",
    "                                         train_features_dict['temp_diff'],\n",
    "                                         train_features_dict['citation_check'],\n",
    "                                         train_features_dict['max_sim'],\n",
    "                                         train_features_dict['peer_popularity'],\n",
    "                                         train_features_dict['edge_check'],\n",
    "                                         train_features_dict['succ_pred'],\n",
    "                                         train_features_dict['LSA_distance'],\n",
    "                                         train_features_dict['title_sim'],\n",
    "                                         train_features_dict['temporal_fit'],\n",
    "                                        train_features_dict['N_LSA_distance']]                                            \n",
    "                                        ,axis = 1)\n",
    "\n",
    "train_features_reduced = np.concatenate([train_features_reduced_dict['overlap_title'],\n",
    "                                         train_features_reduced_dict['comm_auth'],\n",
    "                                         train_features_reduced_dict['temp_diff'],\n",
    "                                         train_features_reduced_dict['citation_check'],\n",
    "                                         train_features_reduced_dict['max_sim'],\n",
    "                                         train_features_reduced_dict['peer_popularity'],\n",
    "                                         train_features_reduced_dict['edge_check'],\n",
    "                                         train_features_reduced_dict['succ_pred'],\n",
    "                                         train_features_reduced_dict['LSA_distance'],\n",
    "                                         train_features_reduced_dict['title_sim'],\n",
    "                                         train_features_reduced_dict['temporal_fit'],\n",
    "                                        train_features_reduced_dict['N_LSA_distance']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "test_features = np.concatenate(        [test_features_dict['overlap_title'],\n",
    "                                        test_features_dict['comm_auth'],\n",
    "                                        test_features_dict['temp_diff'],\n",
    "                                        test_features_dict['citation_check'],\n",
    "                                        test_features_dict['max_sim'],\n",
    "                                        test_features_dict['peer_popularity'],\n",
    "                                        test_features_dict['edge_check'],\n",
    "                                        test_features_dict['succ_pred'],\n",
    "                                        test_features_dict['LSA_distance'],\n",
    "                                        test_features_dict['title_sim'],\n",
    "                                        test_features_dict['temporal_fit'],\n",
    "                                       test_features_dict['N_LSA_distance']]\n",
    "                                        ,axis = 1)\n",
    "\n",
    "\n",
    "competition_features = np.concatenate(  [competition_features_dict['overlap_title'],\n",
    "                                        competition_features_dict['comm_auth'],\n",
    "                                        competition_features_dict['temp_diff'],\n",
    "                                        competition_features_dict['citation_check'],\n",
    "                                        competition_features_dict['max_sim'],\n",
    "                                        competition_features_dict['peer_popularity'],\n",
    "                                        competition_features_dict['edge_check'],\n",
    "                                        competition_features_dict['succ_pred'],\n",
    "                                        competition_features_dict['LSA_distance'],\n",
    "                                        competition_features_dict['title_sim'],\n",
    "                                        competition_features_dict['temporal_fit'],\n",
    "                                        competition_features_dict['N_LSA_distance']]\n",
    "                                        ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures as PF\n",
    "\n",
    "poly = PF(degree=2, interaction_only=False)\n",
    "\n",
    "selection = [23, 1, 2, 8, 13, 16, 20, 22]\n",
    "# selection = list(range(train_features_reduced.shape[1]))\n",
    "\n",
    "train_sp = poly.fit_transform(train_features_reduced[:,selection])\n",
    "test_sp = poly.fit_transform(test_features[:,selection])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "scaler = SS()\n",
    "normalized_train_features_reduced = scaler.fit_transform(train_features_reduced)\n",
    "normalized_test_features = scaler.fit_transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9613692332950254 f1: 0.9640406510277374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.LinearSVC(loss='hinge')\n",
    "# selection = [23, 1, 16, 20, 22, 6, 21]\n",
    "selection = list(range(train_features_reduced.shape[1]))\n",
    "\n",
    "# classifier.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "# preds_svm = list(classifier.predict(test_features[:,selection]))\n",
    "classifier.fit(normalized_train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "preds_svm = list(classifier.predict(normalized_test_features[:,selection]))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_svm)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9622886225578723 f1: 0.9651932780749474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "selection = [ 1,  7,  9, 10, 11, 15, 16, 17, 19, 21, 22, 23]\n",
    "model = lr(penalty='l1').fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "preds_lg = list(model.predict(test_features[:,selection]))\n",
    "\n",
    "# model = lr(penalty='l1').fit(train_sp, train_true_labels)\n",
    "# preds_lg = list(model.predict(test_sp))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argsort(list(map(lambda x: abs(x),model.coef_)))[0][:14]\n",
    "# sorted(list(map(lambda x: abs(x),model.coef_))[0],reverse=True)\n",
    "[poly.powers_[i,:] for i in [31,28,9,17,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9505828271219833 f1: 0.9547313962581966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "selection = [1, 2, 6, 13, 16, 20, 21, 22]\n",
    "nNhbr = KNeighborsClassifier(n_neighbors=9,weights='distance')\n",
    "nNhbr.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "preds_knn = nNhbr.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_knn)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9403053685765884 f1: 0.9460373998219056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# selection = [0, 1, 2, 8, 13, 16, 20, 22]\n",
    "selection = [ 0,  2,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22,23]\n",
    "\n",
    "dTree = DecisionTreeClassifier()\n",
    "dTree.fit(train_features_reduced[:,selection],train_true_labels_reduced) # do Ytrain.ravel() for length one Y values\n",
    "preds_dt = dTree.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_dt)))\n",
    "print('acc:',acc,'f1:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9629697525206233 f1: 0.9658956609826103\n"
     ]
    }
   ],
   "source": [
    "# Joined forces\n",
    "joined_DTree = DecisionTreeClassifier()\n",
    "\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_dt = np.reshape(preds_dt,(len(preds_dt),1))\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_dt],axis=1)\n",
    "\n",
    "joined_DTree.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = joined_DTree.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which features are important?\n",
    "# Histogram of the feature frequency for all selections that reached > 90% acc\n",
    "frequency = [0]*total_num_features\n",
    "\n",
    "num_good_preds = 0\n",
    "min_acc = 0.93\n",
    "for i,acc in enumerate(accs):\n",
    "    if acc > min_acc:\n",
    "        num_good_preds += 1\n",
    "        for f in feature_selections[i]:\n",
    "            frequency[f] += 1\n",
    "#frequency = [freq/num_good_preds for freq in frequency]\n",
    "print(\"\")\n",
    "print(\"number of classifiers: \",len(accs))\n",
    "print(\"number of accs >\",min_acc,\": \",sum([1 for acc in accs if acc > min_acc]))\n",
    "plt.figure()\n",
    "plt.bar(x=range(len(frequency)),height=frequency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.956279757018552 f1: 0.9592158664522552\n"
     ]
    }
   ],
   "source": [
    "# Adaboost DecisionTrees\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=500,learning_rate=0.1)\n",
    "ada.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_ada = ada.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "selection = [23, 1, 2, 8, 13, 16, 20, 22]\n",
    "ada = AdaBoostClassifier(lr(),n_estimators=500,learning_rate=1)\n",
    "ada.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_ada = ada.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_ada)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9645706780495813 f1: 0.9675674050918271\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "#fiddle with n_estimators and min_samples_leaf\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "selection = [1, 2,  5,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "\n",
    "#add one to min_sample_leaf for full train_features (or change to 4)\n",
    "extraTrees = ExtraTreesClassifier(n_estimators=750,max_depth=90,min_samples_split=10,min_samples_leaf=0.00001)\n",
    "extraTrees.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_extra = extraTrees.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_extra)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9663109505828271 f1: 0.9691512071920382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#f1: 0.96989, takes ~35 mins\n",
    "selection = [2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "randForest = RandomForestClassifier(n_estimators = 750, min_samples_split = 5, min_samples_leaf = 4, max_depth = 60)\n",
    "\n",
    "randForest.fit(train_features_reduced[:,selection],train_true_labels_reduced)\n",
    "preds_randForest = randForest.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_randForest)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_randForest)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf = list(preds_rf)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_rf = list(zip(range(len(competition_set)), preds_rf))\n",
    "\n",
    "with open(\"rf_predictions.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_rf:\n",
    "        csv_out.writerow(row)\n",
    "        \n",
    "with open('random_forest_model', 'wb') as file:\n",
    "        pickle.dump(randForest,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9630274175012313 f1: 0.9661180152258299\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "selection = [0, 2, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25]\n",
    "# selection = [ 2, 10, 14, 16, 19, 20, 21, 22, 23]\n",
    "\n",
    "xgb = XGBClassifier(objective= 'binary:logistic', subsample = 0.8, colsample_bytree=0.8, learning_rate=0.01, \n",
    "                     max_depth=5, min_child_weight = 4, gamma=0, reg_lambda=2)\n",
    "\n",
    "xgb.fit(train_features[:,selection],train_true_labels)\n",
    "preds_xgb = xgb.predict(test_features[:,selection])\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels)), list(map(int,preds_xgb)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_xgb)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = list(preds_xgb)\n",
    "\n",
    "# write predictions to .csv file suitable for Kaggle (just make sure to add the column names)\n",
    "preds_xgb = list(zip(range(len(competition_set)), preds_xgb))\n",
    "\n",
    "with open(\"xgb_predictions.csv\",\"w\") as pred1:\n",
    "    csv_out = csv.writer(pred1)\n",
    "    for row in preds_xgb:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5fe441d8fb56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcombined_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_test_svm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_lg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_knn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_et\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds_test_xgb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_true_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpreds_joined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#### NEEDS TO BE FIXED\n",
    "preds_test_svm = np.reshape(preds_svm,(len(preds_svm),1))\n",
    "preds_test_lg = np.reshape(preds_lg,(len(preds_lg),1))\n",
    "preds_test_knn = np.reshape(preds_knn,(len(preds_knn),1))\n",
    "preds_test_et = np.reshape(preds_extra,(len(preds_extra),1))\n",
    "preds_test_xgb = np.reshape(preds_xgb,(len(preds_xgb),1))\n",
    "\n",
    "combined_preds = np.concatenate([preds_test_svm,preds_test_lg,preds_test_knn,preds_test_et,preds_test_xgb],axis=1)\n",
    "\n",
    "VotingClassifier.fit(combined_preds[0:50000,:], test_true_labels[0:50000])\n",
    "preds_joined = VotingClassifier.predict(combined_preds[50000:,:])\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "f1 = metrics.f1_score(list(map(int,test_true_labels[50000:])), list(map(int,preds_joined)))\n",
    "print(\"acc:\",acc,\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]},\n",
    "# tuned_parameters = [{'penalty': ['l1'], 'C': [1, 10], 'loss': ['squared_hinge'],'dual': [False],\n",
    "#                      'max_iter': [1000,5000]}]\n",
    "tuned_parameters = [{'n_estimators': [500],'criterion': ['gini'],'max_depth': [None,50,100],\n",
    "                    'min_samples_split': [2,10], 'min_samples_leaf': [4,0.00001], 'bootstrap': [True, False]}]\n",
    "selection = [1, 2, 6, 13, 16, 20, 22, 23]\n",
    "\n",
    "scores = ['f1_macro'] #'accuracy_score'\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(ExtraTreesClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s' % score)\n",
    "    clf.fit(train_features_reduced[:,selection], train_true_labels_reduced)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = test_true_labels, clf.predict(test_features[:,selection])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 65 candidates, totalling 130 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 130 out of 130 | elapsed: 22.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=65, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 650, 1100, 1550, 2000], 'max_features': ['auto', 'log2'], 'max_depth': [2, 14, 26, 38, 50, 62, 74, 86, 98, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4, 1e-05, 1e-06], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "randForest = RandomForestClassifier()\n",
    "selection = [1, 2, 6, 13, 16, 20, 22, 23,25]\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,0.00001,0.000001]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "criterion = ['gini', 'entropy']\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "                'criterion': criterion}\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator = randForest, param_distributions = random_grid, n_iter = 65,\n",
    "                              cv = 2, verbose = 10, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(train_features_reduced[:,selection], train_true_labels_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9602235845654525,\n",
       " 0.9601875225387667,\n",
       " 0.9601153984853948,\n",
       " 0.9601153984853948,\n",
       " 0.9601153984853948,\n",
       " 0.960079336458709,\n",
       " 0.9600432744320231,\n",
       " 0.9600072124053372,\n",
       " 0.9599711503786513,\n",
       " 0.9599350883519654,\n",
       " 0.9599350883519654,\n",
       " 0.9599350883519654,\n",
       " 0.9599350883519654,\n",
       " 0.9599350883519654,\n",
       " 0.9598990263252795]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "top = np.argsort(rf_random.cv_results_['rank_test_score'])\n",
    "# top[:5]\n",
    "# xgb_random.best_index_\n",
    "mode([rf_random.cv_results_['params'][i]['bootstrap'] for i in top[:15]])\n",
    "[rf_random.cv_results_['mean_test_score'][i] for i in top[:15]]\n",
    "\n",
    "# [{'n_estimators': 1400,\n",
    "#   'min_samples_split': 5,\n",
    "#   'min_samples_leaf': 4,\n",
    "#   'max_features': 'auto',\n",
    "#   'max_depth': 60,\n",
    "#   'criterion': 'gini',\n",
    "#   'bootstrap': True},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 26 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators = 750, min_samples_split = 5, min_samples_leaf = 4, max_depth = 60)\n",
    "# = ExtraTreesClassifier(n_estimators=500,max_depth=50,min_samples_split=10,min_samples_leaf=0.00001)\n",
    "# = DecisionTreeClassifier()\n",
    "# = lr(penalty='l1')\n",
    "# = svm.LinearSVC(loss='hinge',max_iter=10000)\n",
    "\n",
    "random.seed(0)\n",
    "short = random.sample(range(len(train_features_reduced)),10000)\n",
    "\n",
    "selector = RFECV(estimator, step=3, cv=3,min_features_to_select=3,verbose=10)\n",
    "selector = selector.fit(train_features_reduced[short], train_true_labels_reduced[short])\n",
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2,  3,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17, 18, 19,\n",
       "        20, 21, 22, 23, 24, 25]),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(selector.ranking_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "to_del = []\n",
    "gold_all_graph=copy.copy(all_graph)\n",
    "for i,triple in enumerate(training_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "#     index_source = node_dict[source]\n",
    "#     index_target = node_dict[target]\n",
    "#     source_info = node_info[index_source]\n",
    "#     target_info = node_info[index_target]\n",
    "#     temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "#     if temp_diff<-1:\n",
    "    if triple[2]=='0':\n",
    "        to_del.append((source,target))\n",
    "\n",
    "for i,triple in enumerate(testing_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    to_del.append((source,target))\n",
    "        \n",
    "gold_all_graph.delete_edges(to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.241418600082397"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "small = random.sample(testing_set,5000)\n",
    "# shortest_paths = [reduced_train_graph.shortest_paths_dijkstra(source = t[0], target = t[1]) for t in small]\n",
    "sources = list(set([t[0] for t in small]))\n",
    "targets = list(set([t[1] for t in small]))\n",
    "shortest_paths_array = np.array( gold_all_graph.shortest_paths_dijkstra(source = sources, \n",
    "                                                             target = targets,\n",
    "                                                             mode = 'OUT') )\n",
    "\n",
    "# nd_sources = prep.to_dict([s for s in sources],range(len(sources)) )\n",
    "# nd_targets = prep.to_dict([t for t in targets],range(len(targets)) )\n",
    "\n",
    "print(0)\n",
    "\n",
    "shortest_paths_dict = dict(zip( [s for s in sources],\n",
    "    [dict(zip( [t for t in targets], row)) for row in shortest_paths_array] ))\n",
    "\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.25768756866455"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "small2 = random.sample(testing_set,5000)\n",
    "sources2 = list(set([t[0] for t in small2]))\n",
    "targets2 = list(set([t[1] for t in small2]))\n",
    "shortest_paths_array2 = np.array( gold_all_graph.shortest_paths_dijkstra(source = sources2, \n",
    "                                                             target = targets2,\n",
    "                                                             mode = 'OUT') )\n",
    "print(0)\n",
    "\n",
    "shortest_paths_dict2 = dict(zip( [s for s in sources2],\n",
    "    [dict(zip( [t for t in targets2], row)) for row in shortest_paths_array2] ))\n",
    "\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_sources = prep.to_dict([s for s in sources],range(len(sources)) )\n",
    "nd_targets = prep.to_dict([t for t in targets],range(len(targets)) )\n",
    "\n",
    "def path_length(s,t,paths_dict):\n",
    "    '''\n",
    "    @paths_dict: shortest paths nested dict where paths_dict[source_id][target_id] is path distance from source to target\n",
    "    '''\n",
    "    \n",
    "    return paths_dict[s][t]\n",
    "\n",
    "true_pairs = [s for s in small if s[2]=='1']\n",
    "false_pairs = [s for s in small if s[2]=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [min(path_length(s,t,shortest_paths_dict),10000) for (s,t,b) in small]\n",
    "\n",
    "feat2 = [min(path_length(s,t,shortest_paths_dict2),10000) for (s,t,b) in small2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no edge from vertex #18170 to #7629",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-be75247e8077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set_reduced\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgold_train_graph_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/JUPYTER PROJECTS/ML/project/preprocessing.py\u001b[0m in \u001b[0;36mall_paths\u001b[0;34m(pairs_array, gold_graph)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mto_del\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mchunk_removed_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_del\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36mdelete_edges\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0medge_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGraphBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no edge from vertex #18170 to #7629"
     ]
    }
   ],
   "source": [
    "path_dict = prep.all_paths(training_set_reduced,gold_train_graph_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import other_functions as of\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "# of.weighted_overlap(lambda s,t: path_length(s,t,shortest_paths_dict), true_pairs, false_pairs)\n",
    "\n",
    "model = lr(penalty='l1').fit(np.array(feat).reshape(-1,1), np.array(small)[:,2])\n",
    "preds_lg = list(model.predict(np.array(feat2).reshape(-1,1)))\n",
    "\n",
    "# model = lr(penalty='l1').fit(train_sp, train_true_labels)\n",
    "# preds_lg = list(model.predict(test_sp))\n",
    "\n",
    "acc = metrics.accuracy_score(list(map(int,np.array(small2)[:,2])), list(map(int,preds_lg)))\n",
    "# f1 = metrics.f1_score(list(map(int,test_true_labels)), list(map(int,preds_lg)))\n",
    "print('acc:',acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 554602\n",
      "1000 / 554602\n",
      "2000 / 554602\n",
      "3000 / 554602\n",
      "4000 / 554602\n",
      "5000 / 554602\n",
      "6000 / 554602\n",
      "7000 / 554602\n",
      "8000 / 554602\n",
      "9000 / 554602\n",
      "10000 / 554602\n",
      "11000 / 554602\n",
      "12000 / 554602\n",
      "13000 / 554602\n",
      "14000 / 554602\n",
      "15000 / 554602\n",
      "16000 / 554602\n",
      "17000 / 554602\n",
      "18000 / 554602\n",
      "19000 / 554602\n",
      "20000 / 554602\n",
      "21000 / 554602\n",
      "22000 / 554602\n",
      "23000 / 554602\n",
      "24000 / 554602\n",
      "25000 / 554602\n",
      "26000 / 554602\n",
      "27000 / 554602\n",
      "28000 / 554602\n",
      "29000 / 554602\n",
      "30000 / 554602\n",
      "31000 / 554602\n",
      "32000 / 554602\n",
      "33000 / 554602\n",
      "34000 / 554602\n",
      "35000 / 554602\n",
      "36000 / 554602\n",
      "37000 / 554602\n",
      "38000 / 554602\n",
      "39000 / 554602\n",
      "40000 / 554602\n",
      "41000 / 554602\n",
      "42000 / 554602\n",
      "43000 / 554602\n",
      "44000 / 554602\n",
      "45000 / 554602\n",
      "46000 / 554602\n",
      "47000 / 554602\n",
      "48000 / 554602\n",
      "49000 / 554602\n",
      "50000 / 554602\n",
      "51000 / 554602\n",
      "52000 / 554602\n",
      "53000 / 554602\n",
      "54000 / 554602\n",
      "55000 / 554602\n",
      "56000 / 554602\n",
      "57000 / 554602\n",
      "58000 / 554602\n",
      "59000 / 554602\n",
      "60000 / 554602\n",
      "61000 / 554602\n",
      "62000 / 554602\n",
      "63000 / 554602\n",
      "64000 / 554602\n",
      "65000 / 554602\n",
      "66000 / 554602\n",
      "67000 / 554602\n",
      "68000 / 554602\n",
      "69000 / 554602\n",
      "70000 / 554602\n",
      "71000 / 554602\n",
      "72000 / 554602\n",
      "73000 / 554602\n",
      "74000 / 554602\n",
      "75000 / 554602\n",
      "76000 / 554602\n",
      "77000 / 554602\n",
      "78000 / 554602\n",
      "79000 / 554602\n",
      "80000 / 554602\n",
      "81000 / 554602\n",
      "82000 / 554602\n",
      "83000 / 554602\n",
      "84000 / 554602\n",
      "85000 / 554602\n",
      "86000 / 554602\n",
      "87000 / 554602\n",
      "88000 / 554602\n",
      "89000 / 554602\n",
      "90000 / 554602\n",
      "91000 / 554602\n",
      "92000 / 554602\n",
      "93000 / 554602\n",
      "94000 / 554602\n",
      "95000 / 554602\n",
      "96000 / 554602\n",
      "97000 / 554602\n",
      "98000 / 554602\n",
      "99000 / 554602\n",
      "100000 / 554602\n",
      "101000 / 554602\n",
      "102000 / 554602\n",
      "103000 / 554602\n",
      "104000 / 554602\n",
      "105000 / 554602\n",
      "106000 / 554602\n",
      "107000 / 554602\n",
      "108000 / 554602\n",
      "109000 / 554602\n",
      "110000 / 554602\n",
      "111000 / 554602\n",
      "112000 / 554602\n",
      "113000 / 554602\n",
      "114000 / 554602\n",
      "115000 / 554602\n",
      "116000 / 554602\n",
      "117000 / 554602\n",
      "118000 / 554602\n",
      "119000 / 554602\n",
      "120000 / 554602\n",
      "121000 / 554602\n",
      "122000 / 554602\n",
      "123000 / 554602\n",
      "124000 / 554602\n",
      "125000 / 554602\n",
      "126000 / 554602\n",
      "127000 / 554602\n",
      "128000 / 554602\n",
      "129000 / 554602\n",
      "130000 / 554602\n",
      "131000 / 554602\n",
      "132000 / 554602\n",
      "133000 / 554602\n",
      "134000 / 554602\n",
      "135000 / 554602\n",
      "136000 / 554602\n",
      "137000 / 554602\n",
      "138000 / 554602\n",
      "139000 / 554602\n",
      "140000 / 554602\n",
      "141000 / 554602\n",
      "142000 / 554602\n",
      "143000 / 554602\n",
      "144000 / 554602\n",
      "145000 / 554602\n",
      "146000 / 554602\n",
      "147000 / 554602\n",
      "148000 / 554602\n",
      "149000 / 554602\n",
      "150000 / 554602\n",
      "151000 / 554602\n",
      "152000 / 554602\n",
      "153000 / 554602\n",
      "154000 / 554602\n",
      "155000 / 554602\n",
      "156000 / 554602\n",
      "157000 / 554602\n",
      "158000 / 554602\n",
      "159000 / 554602\n",
      "160000 / 554602\n",
      "161000 / 554602\n",
      "162000 / 554602\n",
      "163000 / 554602\n",
      "164000 / 554602\n",
      "165000 / 554602\n",
      "166000 / 554602\n",
      "167000 / 554602\n",
      "168000 / 554602\n",
      "169000 / 554602\n",
      "170000 / 554602\n",
      "171000 / 554602\n",
      "172000 / 554602\n",
      "173000 / 554602\n",
      "174000 / 554602\n",
      "175000 / 554602\n",
      "176000 / 554602\n",
      "177000 / 554602\n",
      "178000 / 554602\n",
      "179000 / 554602\n",
      "180000 / 554602\n",
      "181000 / 554602\n",
      "182000 / 554602\n",
      "183000 / 554602\n",
      "184000 / 554602\n",
      "185000 / 554602\n",
      "186000 / 554602\n",
      "187000 / 554602\n",
      "188000 / 554602\n",
      "189000 / 554602\n",
      "190000 / 554602\n",
      "191000 / 554602\n",
      "192000 / 554602\n",
      "193000 / 554602\n",
      "194000 / 554602\n",
      "195000 / 554602\n",
      "196000 / 554602\n",
      "197000 / 554602\n",
      "198000 / 554602\n",
      "199000 / 554602\n",
      "200000 / 554602\n",
      "201000 / 554602\n",
      "202000 / 554602\n",
      "203000 / 554602\n",
      "204000 / 554602\n",
      "205000 / 554602\n",
      "206000 / 554602\n",
      "207000 / 554602\n",
      "208000 / 554602\n",
      "209000 / 554602\n",
      "210000 / 554602\n",
      "211000 / 554602\n",
      "212000 / 554602\n",
      "213000 / 554602\n",
      "214000 / 554602\n",
      "215000 / 554602\n",
      "216000 / 554602\n",
      "217000 / 554602\n",
      "218000 / 554602\n",
      "219000 / 554602\n",
      "220000 / 554602\n",
      "221000 / 554602\n",
      "222000 / 554602\n",
      "223000 / 554602\n",
      "224000 / 554602\n",
      "225000 / 554602\n",
      "226000 / 554602\n",
      "227000 / 554602\n",
      "228000 / 554602\n",
      "229000 / 554602\n",
      "230000 / 554602\n",
      "231000 / 554602\n",
      "232000 / 554602\n",
      "233000 / 554602\n",
      "234000 / 554602\n",
      "235000 / 554602\n",
      "236000 / 554602\n",
      "237000 / 554602\n",
      "238000 / 554602\n",
      "239000 / 554602\n",
      "240000 / 554602\n",
      "241000 / 554602\n",
      "242000 / 554602\n",
      "243000 / 554602\n",
      "244000 / 554602\n",
      "245000 / 554602\n",
      "246000 / 554602\n",
      "247000 / 554602\n",
      "248000 / 554602\n",
      "249000 / 554602\n",
      "250000 / 554602\n",
      "251000 / 554602\n",
      "252000 / 554602\n",
      "253000 / 554602\n",
      "254000 / 554602\n",
      "255000 / 554602\n",
      "256000 / 554602\n",
      "257000 / 554602\n",
      "258000 / 554602\n",
      "259000 / 554602\n",
      "260000 / 554602\n",
      "261000 / 554602\n",
      "262000 / 554602\n",
      "263000 / 554602\n",
      "264000 / 554602\n",
      "265000 / 554602\n",
      "266000 / 554602\n",
      "267000 / 554602\n",
      "268000 / 554602\n",
      "269000 / 554602\n",
      "270000 / 554602\n",
      "271000 / 554602\n",
      "272000 / 554602\n",
      "273000 / 554602\n",
      "274000 / 554602\n",
      "275000 / 554602\n",
      "276000 / 554602\n",
      "277000 / 554602\n",
      "278000 / 554602\n",
      "279000 / 554602\n",
      "280000 / 554602\n",
      "281000 / 554602\n",
      "282000 / 554602\n",
      "283000 / 554602\n",
      "284000 / 554602\n",
      "285000 / 554602\n",
      "286000 / 554602\n",
      "287000 / 554602\n",
      "288000 / 554602\n",
      "289000 / 554602\n",
      "290000 / 554602\n",
      "291000 / 554602\n",
      "292000 / 554602\n",
      "293000 / 554602\n",
      "294000 / 554602\n",
      "295000 / 554602\n",
      "296000 / 554602\n",
      "297000 / 554602\n",
      "298000 / 554602\n",
      "299000 / 554602\n",
      "300000 / 554602\n",
      "301000 / 554602\n",
      "302000 / 554602\n",
      "303000 / 554602\n",
      "304000 / 554602\n",
      "305000 / 554602\n",
      "306000 / 554602\n",
      "307000 / 554602\n",
      "308000 / 554602\n",
      "309000 / 554602\n",
      "310000 / 554602\n",
      "311000 / 554602\n",
      "312000 / 554602\n",
      "313000 / 554602\n",
      "314000 / 554602\n",
      "315000 / 554602\n",
      "316000 / 554602\n",
      "317000 / 554602\n",
      "318000 / 554602\n",
      "319000 / 554602\n",
      "320000 / 554602\n",
      "321000 / 554602\n",
      "322000 / 554602\n",
      "323000 / 554602\n",
      "324000 / 554602\n",
      "325000 / 554602\n",
      "326000 / 554602\n",
      "327000 / 554602\n",
      "328000 / 554602\n",
      "329000 / 554602\n",
      "330000 / 554602\n",
      "331000 / 554602\n",
      "332000 / 554602\n",
      "333000 / 554602\n",
      "334000 / 554602\n",
      "335000 / 554602\n",
      "336000 / 554602\n",
      "337000 / 554602\n",
      "338000 / 554602\n",
      "339000 / 554602\n",
      "340000 / 554602\n",
      "341000 / 554602\n",
      "342000 / 554602\n",
      "343000 / 554602\n",
      "344000 / 554602\n",
      "345000 / 554602\n",
      "346000 / 554602\n",
      "347000 / 554602\n",
      "348000 / 554602\n",
      "349000 / 554602\n",
      "350000 / 554602\n",
      "351000 / 554602\n",
      "352000 / 554602\n",
      "353000 / 554602\n",
      "354000 / 554602\n",
      "355000 / 554602\n",
      "356000 / 554602\n",
      "357000 / 554602\n",
      "358000 / 554602\n",
      "359000 / 554602\n",
      "360000 / 554602\n",
      "361000 / 554602\n",
      "362000 / 554602\n",
      "363000 / 554602\n",
      "364000 / 554602\n",
      "365000 / 554602\n",
      "366000 / 554602\n",
      "367000 / 554602\n",
      "368000 / 554602\n",
      "369000 / 554602\n",
      "370000 / 554602\n",
      "371000 / 554602\n",
      "372000 / 554602\n",
      "373000 / 554602\n",
      "374000 / 554602\n",
      "375000 / 554602\n",
      "376000 / 554602\n",
      "377000 / 554602\n",
      "378000 / 554602\n",
      "379000 / 554602\n",
      "380000 / 554602\n",
      "381000 / 554602\n",
      "382000 / 554602\n",
      "383000 / 554602\n",
      "384000 / 554602\n",
      "385000 / 554602\n",
      "386000 / 554602\n",
      "387000 / 554602\n",
      "388000 / 554602\n",
      "389000 / 554602\n",
      "390000 / 554602\n",
      "391000 / 554602\n",
      "392000 / 554602\n",
      "393000 / 554602\n",
      "394000 / 554602\n",
      "395000 / 554602\n",
      "396000 / 554602\n",
      "397000 / 554602\n",
      "398000 / 554602\n",
      "399000 / 554602\n",
      "400000 / 554602\n",
      "401000 / 554602\n",
      "402000 / 554602\n",
      "403000 / 554602\n",
      "404000 / 554602\n",
      "405000 / 554602\n",
      "406000 / 554602\n",
      "407000 / 554602\n",
      "408000 / 554602\n",
      "409000 / 554602\n",
      "410000 / 554602\n",
      "411000 / 554602\n",
      "412000 / 554602\n",
      "413000 / 554602\n",
      "414000 / 554602\n",
      "415000 / 554602\n",
      "416000 / 554602\n",
      "417000 / 554602\n",
      "418000 / 554602\n",
      "419000 / 554602\n",
      "420000 / 554602\n",
      "421000 / 554602\n",
      "422000 / 554602\n",
      "423000 / 554602\n",
      "424000 / 554602\n",
      "425000 / 554602\n",
      "426000 / 554602\n",
      "427000 / 554602\n",
      "428000 / 554602\n",
      "429000 / 554602\n",
      "430000 / 554602\n",
      "431000 / 554602\n",
      "432000 / 554602\n",
      "433000 / 554602\n",
      "434000 / 554602\n",
      "435000 / 554602\n",
      "436000 / 554602\n",
      "437000 / 554602\n",
      "438000 / 554602\n",
      "439000 / 554602\n",
      "440000 / 554602\n",
      "441000 / 554602\n",
      "442000 / 554602\n",
      "443000 / 554602\n",
      "444000 / 554602\n",
      "445000 / 554602\n",
      "446000 / 554602\n",
      "447000 / 554602\n",
      "448000 / 554602\n",
      "449000 / 554602\n",
      "450000 / 554602\n",
      "451000 / 554602\n",
      "452000 / 554602\n",
      "453000 / 554602\n",
      "454000 / 554602\n",
      "455000 / 554602\n",
      "456000 / 554602\n",
      "457000 / 554602\n",
      "458000 / 554602\n",
      "459000 / 554602\n",
      "460000 / 554602\n",
      "461000 / 554602\n",
      "462000 / 554602\n",
      "463000 / 554602\n",
      "464000 / 554602\n",
      "465000 / 554602\n",
      "466000 / 554602\n",
      "467000 / 554602\n",
      "468000 / 554602\n",
      "469000 / 554602\n",
      "470000 / 554602\n",
      "471000 / 554602\n",
      "472000 / 554602\n",
      "473000 / 554602\n",
      "474000 / 554602\n",
      "475000 / 554602\n",
      "476000 / 554602\n",
      "477000 / 554602\n",
      "478000 / 554602\n",
      "479000 / 554602\n",
      "480000 / 554602\n",
      "481000 / 554602\n",
      "482000 / 554602\n",
      "483000 / 554602\n",
      "484000 / 554602\n",
      "485000 / 554602\n",
      "486000 / 554602\n",
      "487000 / 554602\n",
      "488000 / 554602\n",
      "489000 / 554602\n",
      "490000 / 554602\n",
      "491000 / 554602\n",
      "492000 / 554602\n",
      "493000 / 554602\n",
      "494000 / 554602\n",
      "495000 / 554602\n",
      "496000 / 554602\n",
      "497000 / 554602\n",
      "498000 / 554602\n",
      "499000 / 554602\n",
      "500000 / 554602\n",
      "501000 / 554602\n",
      "502000 / 554602\n",
      "503000 / 554602\n",
      "504000 / 554602\n",
      "505000 / 554602\n",
      "506000 / 554602\n",
      "507000 / 554602\n",
      "508000 / 554602\n",
      "509000 / 554602\n",
      "510000 / 554602\n",
      "511000 / 554602\n",
      "512000 / 554602\n",
      "513000 / 554602\n",
      "514000 / 554602\n",
      "515000 / 554602\n",
      "516000 / 554602\n",
      "517000 / 554602\n",
      "518000 / 554602\n",
      "519000 / 554602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520000 / 554602\n",
      "521000 / 554602\n",
      "522000 / 554602\n",
      "523000 / 554602\n",
      "524000 / 554602\n",
      "525000 / 554602\n",
      "526000 / 554602\n",
      "527000 / 554602\n",
      "528000 / 554602\n",
      "529000 / 554602\n",
      "530000 / 554602\n",
      "531000 / 554602\n",
      "532000 / 554602\n",
      "533000 / 554602\n",
      "534000 / 554602\n",
      "535000 / 554602\n",
      "536000 / 554602\n",
      "537000 / 554602\n",
      "538000 / 554602\n",
      "539000 / 554602\n",
      "540000 / 554602\n",
      "541000 / 554602\n",
      "542000 / 554602\n",
      "543000 / 554602\n",
      "544000 / 554602\n",
      "545000 / 554602\n",
      "546000 / 554602\n",
      "547000 / 554602\n",
      "548000 / 554602\n",
      "549000 / 554602\n",
      "550000 / 554602\n",
      "551000 / 554602\n",
      "552000 / 554602\n",
      "553000 / 554602\n",
      "554000 / 554602\n",
      "overlap_title 27730\n",
      "comm_auth 27730\n",
      "temp_diff 27730\n",
      "citation_check 27730\n",
      "max_sim 27730\n",
      "peer_popularity 27730\n",
      "edge_check 27730\n",
      "LSA_distance 27730\n",
      "node_degree 27730\n",
      "succ_pred 27730\n",
      "title_sim 27730\n",
      "temporal_fit 27730\n",
      "N_LSA_distance 554602\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "###  Construct features on TRAINING_SET  ###\n",
    "############################################\n",
    "\n",
    "#Build KDTree on training_set\n",
    "train_l = [l[node_dict[i]] for i in train_IDs]\n",
    "train_kdtree = nw.KDTree(train_l)\n",
    "\n",
    "train_true_labels = []\n",
    "features_to_create = ['N_LSA_distance']\n",
    "#'peer_popularity', 'max_sim', 'edge_check', 'title_sim', 'citation_check', 'node_degree','succ_pred', \n",
    "    \n",
    "# Where to insert created features\n",
    "insert_features_dict = train_features_reduced_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = training_set\n",
    "title_sim_ones = []\n",
    "title_sim_zeros = []\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    #overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    #insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    #temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    #insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    #comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    #insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(reduced_train_graph,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,reduced_train_graph,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,reduced_train_graph)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "    #LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    #insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     title_weighted = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "#     if(int(triple[2]) == 0):\n",
    "#         title_sim_zeros.append(title_weighted)\n",
    "#     else:\n",
    "#         title_sim_ones.append(title_weighted)\n",
    "#     citation_check = pw.Citation_Check(source,target,train_kdtree,l,reduced_train_graph,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "\n",
    "#     degree = pw.node_degree(source,target,reduced_train_graph)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "\n",
    "#     succ_pred = pw.succ_pred(source,target,reduced_train_graph)\n",
    "#     insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "    \n",
    "#     train_true_labels.append(triple[2])\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "    \n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_train/'+feat)\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_train = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# train_true_labels = np.array(train_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './features_train/'+'max_sim'+'_reducedgraph'\n",
    "try:\n",
    "    this_feat = read_feature(file_path)\n",
    "except:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del = []\n",
    "reduced_all_graph=copy.copy(all_graph)\n",
    "for i,triple in enumerate(testing_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    if temp_diff<-1:\n",
    "        to_del.append((source,target))\n",
    "        \n",
    "for i,triple in enumerate(training_set):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "    temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    if temp_diff<-1:\n",
    "        to_del.append((source,target))\n",
    "\n",
    "\n",
    "reduced_all_graph.delete_edges(to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 60910\n",
      "1000 / 60910\n",
      "2000 / 60910\n",
      "3000 / 60910\n",
      "4000 / 60910\n",
      "5000 / 60910\n",
      "6000 / 60910\n",
      "7000 / 60910\n",
      "8000 / 60910\n",
      "9000 / 60910\n",
      "10000 / 60910\n",
      "11000 / 60910\n",
      "12000 / 60910\n",
      "13000 / 60910\n",
      "14000 / 60910\n",
      "15000 / 60910\n",
      "16000 / 60910\n",
      "17000 / 60910\n",
      "18000 / 60910\n",
      "19000 / 60910\n",
      "20000 / 60910\n",
      "21000 / 60910\n",
      "22000 / 60910\n",
      "23000 / 60910\n",
      "24000 / 60910\n",
      "25000 / 60910\n",
      "26000 / 60910\n",
      "27000 / 60910\n",
      "28000 / 60910\n",
      "29000 / 60910\n",
      "30000 / 60910\n",
      "31000 / 60910\n",
      "32000 / 60910\n",
      "33000 / 60910\n",
      "34000 / 60910\n",
      "35000 / 60910\n",
      "36000 / 60910\n",
      "37000 / 60910\n",
      "38000 / 60910\n",
      "39000 / 60910\n",
      "40000 / 60910\n",
      "41000 / 60910\n",
      "42000 / 60910\n",
      "43000 / 60910\n",
      "44000 / 60910\n",
      "45000 / 60910\n",
      "46000 / 60910\n",
      "47000 / 60910\n",
      "48000 / 60910\n",
      "49000 / 60910\n",
      "50000 / 60910\n",
      "51000 / 60910\n",
      "52000 / 60910\n",
      "53000 / 60910\n",
      "54000 / 60910\n",
      "55000 / 60910\n",
      "56000 / 60910\n",
      "57000 / 60910\n",
      "58000 / 60910\n",
      "59000 / 60910\n",
      "60000 / 60910\n",
      "overlap_title 60910\n",
      "comm_auth 60910\n",
      "temp_diff 60910\n",
      "citation_check 60910\n",
      "max_sim 60910\n",
      "peer_popularity 60910\n",
      "edge_check 60910\n",
      "LSA_distance 60910\n",
      "node_degree 60910\n",
      "succ_pred 60910\n",
      "title_sim 60910\n",
      "temporal_fit 60910\n",
      "N_LSA_distance 60910\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'write_feature_to_disk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-53637b82a0e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_to_create\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mwrite_feature_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_features_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./features_test/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'write_feature_to_disk' is not defined"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "###  Construct features on TESTING_SET  ###\n",
    "###########################################\n",
    "\n",
    "#Build KDTree on training_set\n",
    "kdtree = nw.KDTree(l)\n",
    "\n",
    "train_true_labels = []\n",
    "features_to_create = ['N_LSA_distance']\n",
    "#'peer_popularity', 'max_sim', 'edge_check', 'title_sim', 'citation_check','node_degree','succ_pred',\n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = test_features_dict\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = testing_set\n",
    "\n",
    "test_true_labels = []\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "    #overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "    #insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "    #temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "    #insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "    #comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "    #insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(reduced_all_graph,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,reduced_all_graph,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,reduced_all_graph)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "    #LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "    #insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     title_weighted = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(title_weighted)\n",
    "    \n",
    "#     citation_check = pw.Citation_Check(source,target,kdtree,l,reduced_all_graph,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "    \n",
    "#     succ_pred = pw.succ_pred(source,target,reduced_all_graph)\n",
    "#     insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "#     degree = pw.node_degree(source,target,reduced_all_graph)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "    \n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "#     test_true_labels.append(triple[2])\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_test = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# test_true_labels = np.array(test_true_labels)\n",
    "\n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_test/'+feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 32648\n",
      "1000 / 32648\n",
      "2000 / 32648\n",
      "3000 / 32648\n",
      "4000 / 32648\n",
      "5000 / 32648\n",
      "6000 / 32648\n",
      "7000 / 32648\n",
      "8000 / 32648\n",
      "9000 / 32648\n",
      "10000 / 32648\n",
      "11000 / 32648\n",
      "12000 / 32648\n",
      "13000 / 32648\n",
      "14000 / 32648\n",
      "15000 / 32648\n",
      "16000 / 32648\n",
      "17000 / 32648\n",
      "18000 / 32648\n",
      "19000 / 32648\n",
      "20000 / 32648\n",
      "21000 / 32648\n",
      "22000 / 32648\n",
      "23000 / 32648\n",
      "24000 / 32648\n",
      "25000 / 32648\n",
      "26000 / 32648\n",
      "27000 / 32648\n",
      "28000 / 32648\n",
      "29000 / 32648\n",
      "30000 / 32648\n",
      "31000 / 32648\n",
      "32000 / 32648\n",
      "N_LSA_distance 32648\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "###  Construct features on COMPETITION_SET  ###\n",
    "###########################################\n",
    "\n",
    "#Build KDTree on training_set\n",
    "kdtree = nw.KDTree(l)\n",
    "\n",
    "features_to_create = [\"N_LSA_distance\"]\n",
    "# \"overlap_title\",\n",
    "#                  \"comm_auth\",\n",
    "#                  \"temp_diff\",\n",
    "#                 \"citation_check\",\n",
    "#                 \"max_sim\",\n",
    "#                 \"peer_popularity\",\n",
    "#                 \"edge_check\",\n",
    "#                 \"LSA_distance\",\n",
    "#                 \"node_degree\",\n",
    "#                 \"succ_pred\",\n",
    "#                 \"title_sim\",\n",
    "#                 \"temporal_fit\",\n",
    "\n",
    "# Where to insert created features\n",
    "insert_features_dict = dict()\n",
    "for feat in features_to_create:\n",
    "    insert_features_dict[feat] = []\n",
    "set_to_use = competition_set\n",
    "\n",
    "for i,triple in enumerate(set_to_use):\n",
    "    source = triple[0]\n",
    "    target = triple[1]\n",
    "    index_source = node_dict[source]\n",
    "    index_target = node_dict[target]\n",
    "    \n",
    "    source_info = node_info[index_source]\n",
    "    target_info = node_info[index_target]\n",
    "\n",
    "    # convert to lowercase and tokenize\n",
    "    source_title = source_info[2].lower().split(\" \")\n",
    "    # remove stopwords\n",
    "    source_title = [token for token in source_title if token not in stpwds]\n",
    "    source_title = [stemmer.stem(token) for token in source_title]\n",
    "\n",
    "    target_title = target_info[2].lower().split(\" \")\n",
    "    target_title = [token for token in target_title if token not in stpwds]\n",
    "    target_title = [stemmer.stem(token) for token in target_title]\n",
    "\n",
    "    source_auth = source_info[3].split(\",\")\n",
    "    target_auth = target_info[3].split(\",\") \n",
    "    \n",
    "    \n",
    "    # Creating features\n",
    "    # Baseline #\n",
    "#     overlap_title = len(set(source_title).intersection(set(target_title)))\n",
    "#     insert_features_dict[\"overlap_title\"].append(overlap_title)\n",
    "#     temp_diff = int(source_info[1]) - int(target_info[1])\n",
    "#     insert_features_dict[\"temp_diff\"].append(temp_diff)\n",
    "#     comm_auth = len(set(source_auth).intersection(set(target_auth)))\n",
    "#     insert_features_dict[\"comm_auth\"].append(comm_auth)\n",
    "\n",
    "#     peer_pop = pw.peer_popularity(competition_graph_reduced,source,target)\n",
    "#     insert_features_dict[\"peer_popularity\"].append(peer_pop)\n",
    "\n",
    "#     max_sim = pw.Max_Sim(source,target,l,competition_graph_reduced,node_dict)\n",
    "#     insert_features_dict[\"max_sim\"].append(max_sim)\n",
    "\n",
    "#     edge_check = pw.edge_check(source,target,competition_graph_reduced)\n",
    "#     insert_features_dict[\"edge_check\"].append(edge_check)\n",
    "\n",
    "#     LSA_dist = pw.LSA_distance(source,target,node_dict,l)\n",
    "#     insert_features_dict[\"LSA_distance\"].append(LSA_dist)\n",
    "    \n",
    "#     citation_check = pw.Citation_Check(source,target,kdtree,l,competition_graph_reduced,node_dict,index_dict,k=500)\n",
    "#     insert_features_dict[\"citation_check\"].append(citation_check)\n",
    "    \n",
    "#     succ_pred = pw.succ_pred(source,target,competition_graph_reduced)\n",
    "#     insert_features_dict[\"succ_pred\"].append(succ_pred)\n",
    "    \n",
    "#     degree = pw.node_degree(source,target,competition_graph_reduced)\n",
    "#     insert_features_dict[\"node_degree\"].append(degree)\n",
    "    \n",
    "#     ts = title_sim[index_source,index_target]\n",
    "#     insert_features_dict[\"title_sim\"].append(ts)\n",
    "    \n",
    "#     temporal_fit = pw.temp_fit(source,target,competition_graph_reduced,node_dict,publication_years)\n",
    "#     insert_features_dict[\"temporal_fit\"].append(temporal_fit)\n",
    "    \n",
    "    N_LSA_dist = pw.LSA_distance(source,target,node_dict,l_ngrams)\n",
    "    insert_features_dict[\"N_LSA_distance\"].append(N_LSA_dist)\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(i,\"/\",len(set_to_use))\n",
    "\n",
    "# Reshape features into np column arrays, one row per node pair\n",
    "for (name,value) in insert_features_dict.items():\n",
    "    print(name,len(value))\n",
    "    insert_features_dict[name] = to_feature_shape(value)\n",
    "        \n",
    "# Concatenate all features\n",
    "# feats_test = np.concatenate([feat for feat in insert_features_dict.values()])\n",
    "# test_true_labels = np.array(test_true_labels)\n",
    "\n",
    "for feat in features_to_create:\n",
    "    write_feature_to_disk(insert_features_dict[feat],'./features_competition/'+feat+'_reducedgraph')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
